{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1b1d257-2cbb-4c01-b067-aafa08033571",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "import torch\n",
    "from torch_geometric.data import Dataset, Data, DataLoader\n",
    "from torch_geometric import loader\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import torch.nn as nn\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, ReLU\n",
    "import torch.nn.functional as F\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.nn import GATConv, GCNConv, GINConv, MFConv, SAGEConv\n",
    "from torch_geometric.nn import global_add_pool\n",
    "from torch.utils.data import random_split\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.utils import from_networkx\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, accuracy_score, precision_score, f1_score, recall_score, jaccard_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d68a033-cd49-4735-b5bb-d39976276e0d",
   "metadata": {},
   "source": [
    "# 0 DataProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e98369-9c42-42dc-a0fc-e95fc9d1ea4b",
   "metadata": {},
   "source": [
    "## 0.1 Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48f79b4d-f95f-4609-96e2-6428bf9e428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datapath = '../data/train_datsets.pkl'\n",
    "test_datapath = '../data/test_datsets.pkl'\n",
    "fr = open(train_datapath, 'rb')\n",
    "train_data = pickle.load(fr)\n",
    "fe = open(test_datapath, 'rb')\n",
    "test_data = pickle.load(fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57f89a7-2614-4d38-8ed9-19a1a806792d",
   "metadata": {},
   "source": [
    "## 0.2 Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ff25af0-e728-471d-b318-4987c8997c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_list = {}\n",
    "test_data_list = {}\n",
    "for i in range(1, 9):\n",
    "    binNumber = bin(i)[2:].zfill(3)\n",
    "    traits_ = ''.join(binNumber)\n",
    "    new_train_data = []\n",
    "    new_test_data = []\n",
    "    for index, train_ in enumerate(train_data):\n",
    "        # Initialize data_ as an empty tensor\n",
    "        train_data_ = None\n",
    "        train_x_10 = train_.x[:, :10]\n",
    "        train_x_16 = train_.x[:, 10:26]\n",
    "        train_x_3 = train_.x[:, 26:]\n",
    "        if traits_[0] == '1':\n",
    "            train_data_ = train_x_10\n",
    "        if traits_[1] == '1':\n",
    "            train_data_ = torch.cat((train_data_, train_x_16), dim=1) if train_data_ is not None else train_x_16 \n",
    "        if traits_[2] == '1':\n",
    "            train_data_ = torch.cat((train_data_, train_x_3), dim=1) if train_data_ is not None else train_x_3\n",
    "        new_data_ = Data(\n",
    "            x=train_data_,\n",
    "            edge_index=train_.edge_index,\n",
    "            edge_attr=train_.edge_attr,\n",
    "            y=train_.y,\n",
    "            target=train_.target,\n",
    "            name=train_.name,\n",
    "            n_index=train_.n_index,\n",
    "            subgraph_node1=train_.subgraph_node1,\n",
    "            subgraph_node2=train_.subgraph_node2\n",
    "        )\n",
    "        new_train_data.append(new_data_)\n",
    "    train_data_list[traits_] = new_train_data\n",
    "    for test_ in test_data:\n",
    "        # Initialize data_ as an empty tensor\n",
    "        test_data_ = None\n",
    "        test_x_10 = test_.x[:, :10]\n",
    "        test_x_16 = test_.x[:, 10:26]\n",
    "        test_x_3 = test_.x[:, 26:]\n",
    "        if traits_[0] == '1':\n",
    "            test_data_ = test_x_10\n",
    "        if traits_[1] == '1':\n",
    "            test_data_ = torch.cat((test_data_, test_x_16), dim=1) if test_data_ is not None else test_x_16 \n",
    "        if traits_[2] == '1':\n",
    "            test_data_ = torch.cat((test_data_, test_x_3), dim=1) if test_data_ is not None != 0 else test_x_3 \n",
    "        new_data_ = Data(\n",
    "            x=test_data_,\n",
    "            edge_index=test_.edge_index,\n",
    "            edge_attr=test_.edge_attr,\n",
    "            y=test_.y,\n",
    "            target=test_.target,\n",
    "            name=test_.name,\n",
    "            n_index=test_.n_index,\n",
    "            subgraph_node1=test_.subgraph_node1,\n",
    "            subgraph_node2=test_.subgraph_node2\n",
    "        )\n",
    "        new_test_data.append(new_data_)\n",
    "    test_data_list[traits_] = new_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a9bbba-c943-4ee9-a2b8-acc10840acd1",
   "metadata": {},
   "source": [
    "## 0.3 Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b6ff1ef-8486-47ad-9544-f59ce5acf83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader_data(train_data, test_data, batch_size):\n",
    "    training_set, validation_set = random_split(train_data, [int(len(train_data) * 0.85), len(train_data) - int(len(train_data) * 0.85)], generator=torch.Generator().manual_seed(12345))\n",
    "    train_loader = loader.DataLoader(training_set, batch_size, shuffle=True)\n",
    "    val_loader = loader.DataLoader(validation_set, batch_size, shuffle=True)\n",
    "    test_loader = loader.DataLoader(test_data, batch_size, shuffle=False)\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53102d6-b39d-4294-bce7-0a51672aa82c",
   "metadata": {},
   "source": [
    "## 0.4 Set constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "011e3dc0-288c-466e-b952-c1b95b6e20bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_NUMBERS = 12345 # Random numbers\n",
    "batchSize = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a861549-e3dc-4549-a36d-15a4ec9a53e2",
   "metadata": {},
   "source": [
    "## 0.5 Set a random number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e1d1eb9-2c34-4f9a-a1da-c95b800cb526",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.inf)\n",
    "def seed_torch(seed=RANDOM_NUMBERS):\n",
    "    # Seeding ensures that the same random number \n",
    "    # is generated every time you run the code.\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) \n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f617e261-8234-4c14-9a73-95c9c093b148",
   "metadata": {},
   "source": [
    "# 1 Set up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba157222-5ed6-40e5-af28-b48b566290ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALLModel(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(ALLModel, self).__init__()\n",
    "        num_classes = 2\n",
    "\n",
    "        conv_hidden = args['conv_hidden']\n",
    "        traits_number = args['traits_number']\n",
    "        cls_hidden = args['cls_hidden']\n",
    "        self.layer_number = args['layer_number']\n",
    "        self.device = args['device']\n",
    "        self.conv = nn.ModuleList()\n",
    "        if args['model_name'] != 'GIN':\n",
    "            for i in range(self.layer_number):\n",
    "                if i == 0:\n",
    "                    self.conv.append(args['conv'](traits_number, conv_hidden))\n",
    "                else:\n",
    "                    self.conv.append(args['conv'](conv_hidden, conv_hidden))\n",
    "        else:\n",
    "            from torch.nn import Sequential as Seq, Linear as Lin, ReLU\n",
    "            for i in range(self.layer_number):\n",
    "                if i == 0:\n",
    "                    nn_ = Seq(Lin(traits_number, conv_hidden), ReLU(), Lin(conv_hidden, conv_hidden))\n",
    "                    self.conv.append(args['conv'](nn_))\n",
    "                else:\n",
    "                    nn_ = Seq(Lin(conv_hidden, conv_hidden), ReLU(), Lin(conv_hidden, conv_hidden))\n",
    "                    self.conv.append(args['conv'](nn_))\n",
    "\n",
    "        self.conv = self.conv.to(self.device)\n",
    "        \n",
    "        self.linear1 = nn.Linear(conv_hidden, cls_hidden)\n",
    "        self.linear2 = nn.Linear(cls_hidden, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drop1 = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, mol):\n",
    "        x = mol.x.to(self.device)\n",
    "        edge_index = mol.edge_index.to(self.device)\n",
    "        res = x\n",
    "        for i in range(self.layer_number):\n",
    "            res = self.conv[i](res, edge_index)\n",
    "        \n",
    "        res = self.linear1(res)\n",
    "        res = self.relu(res)\n",
    "        res = self.drop1(res)\n",
    "        res = self.linear2(res)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff8e8fa-9d90-4297-9fa9-0deca444ac45",
   "metadata": {},
   "source": [
    "# 2 Set up evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62783958-fe1c-4dd6-a004-c64a48802f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top2(output, label):\n",
    "    sf = nn.Softmax(dim=1)\n",
    "    preds = sf(output)\n",
    "    preds = preds[:, 1]\n",
    "    _, indices = torch.topk(preds, 2)\n",
    "    pos_index = []\n",
    "    for i in range(label.shape[0]):\n",
    "        if label[i] == 1:\n",
    "            pos_index.append(i)  \n",
    "    for li in pos_index:\n",
    "        if li in indices:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def MCC(output, label):\n",
    "    tn,fp,fn,tp=confusion_matrix(label, output).ravel()\n",
    "    up = (tp * tn) - (fp * fn)\n",
    "    down = ((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)) ** 0.5\n",
    "    if down == 0: down = 1e-10\n",
    "    return up / down\n",
    "\n",
    "def metrics(output, label):\n",
    "    tn,fp,fn,tp=confusion_matrix(label, output).ravel()\n",
    "    up = (tp * tn) - (fp * fn)\n",
    "    down = ((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)) ** 0.5\n",
    "    if down == 0: down = 1e-10\n",
    "    mcc = up / down\n",
    "    selectivity = tn / (tn + fp + 1e-10)\n",
    "    recall = tp / (tp + fn + 1e-10)\n",
    "    g_mean = (selectivity * recall) ** 0.5\n",
    "    balancedAccuracy = (recall + selectivity) / 2\n",
    "    return mcc, selectivity, recall, g_mean, balancedAccuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dddefec-c06d-4b61-af5a-d2b40e1217ac",
   "metadata": {},
   "source": [
    "# 3 Model manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0c14f1-8725-447e-a398-0ecbcda6d88e",
   "metadata": {},
   "source": [
    "## 3.1 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd3ff710-081a-4a8f-bbc4-eab21db72093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, training_set, optimizer, criterion):\n",
    "    model.train()\n",
    "    sf = nn.Softmax(dim=1)\n",
    "    total_loss = 0\n",
    "    all_pred = []\n",
    "    all_pred_raw = []\n",
    "    all_labels = []\n",
    "    top2n = 0\n",
    "    model = model.to(args['device'])\n",
    "    for mol in training_set:\n",
    "        mol = mol.to(args['device'])\n",
    "        mol.x = mol.x.to(torch.float32)\n",
    "        target = mol.y\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(mol)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # tracking\n",
    "        top2n += top2(output, target)\n",
    "        all_pred.append(np.argmax(output.cpu().detach().numpy(), axis=1))\n",
    "        all_pred_raw.append(sf(output)[:, 1].cpu().detach().numpy())\n",
    "        all_labels.append(target.cpu().detach().numpy())\n",
    "\n",
    "    all_pred = np.concatenate(all_pred).ravel()\n",
    "    all_pred_raw = np.concatenate(all_pred_raw).ravel()\n",
    "    all_labels = np.concatenate(all_labels).ravel()\n",
    "    mcc, selectivity, recall, g_mean, balanced_acc = metrics(all_pred, all_labels)\n",
    "    train_data_frame = pd.DataFrame(\n",
    "        [{\n",
    "            'Layer': args['layer_number'],\n",
    "            'Feature': args['traits_number_str'],\n",
    "            'Round': args['current_epoch'],\n",
    "            'Model': args['model_name'],\n",
    "            'ACC': accuracy_score(all_labels, all_pred),\n",
    "            'Ave_loss': total_loss / len(training_set),\n",
    "            'Top2': top2n / len(training_set),\n",
    "            'AUC': roc_auc_score(all_labels, all_pred_raw),\n",
    "            'MCC': mcc,\n",
    "            'Jaccard': jaccard_score(all_labels, all_pred),\n",
    "            'Precision': precision_score(all_labels, all_pred, zero_division=args['zero_division']),\n",
    "            'Recall': recall,\n",
    "            'F1': f1_score(all_labels, all_pred),\n",
    "            'Selectivity': selectivity,\n",
    "            'G_mean': g_mean,\n",
    "            'Balanced_acc': balanced_acc,\n",
    "        }],\n",
    "        columns=['Layer', 'Feature', 'Round', 'Model', 'ACC', 'Ave_loss', 'Top2', 'AUC', 'MCC', 'Jaccard', 'Precision', 'Recall', 'F1', 'Selectivity', 'G_mean', 'Balanced_acc'],\n",
    "        index=[0],\n",
    "    )\n",
    "    # train_data_frame.to_csv(args['train_result_path'])\n",
    "    return train_data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7547be90-b20d-40ea-a070-4346d08fd701",
   "metadata": {},
   "source": [
    "## 3.2 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b8c9a04-4c0b-4fca-bbaf-a12bcd00ec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model, device, val_set, optimizer, criterion):\n",
    "    model.eval()\n",
    "    sf = nn.Softmax(dim=1)\n",
    "    top2n = 0\n",
    "    for mol in val_set:\n",
    "        mol = mol.to(device)\n",
    "        mol.x = mol.x.to(torch.float32)\n",
    "        target = mol.y\n",
    "        optimizer.zero_grad()\n",
    "        output = model(mol).to(device)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # tracking\n",
    "        top2n += top2(output, target)\n",
    "    return top2n / len(val_set)\n",
    "\n",
    "def val2(\n",
    "    args,\n",
    "    model,\n",
    "    val_set, \n",
    "    optimizer, \n",
    "    criterion,\n",
    "):\n",
    "    model.eval()\n",
    "    sf = nn.Softmax(dim=1)\n",
    "    total_loss = 0\n",
    "    all_pred = []\n",
    "    all_pred_raw = []\n",
    "    all_labels = []\n",
    "    top2n = 0\n",
    "    for mol in val_set:\n",
    "        mol = mol.to(args['device'])\n",
    "        mol.x = mol.x.to(torch.float32)\n",
    "        target = mol.y\n",
    "        optimizer.zero_grad()\n",
    "        output = model(mol)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        # tracking\n",
    "        top2n += top2(output, target)\n",
    "        all_pred.append(np.argmax(output.cpu().detach().numpy(), axis=1))\n",
    "        all_pred_raw.append(sf(output)[:, 1].cpu().detach().numpy())\n",
    "        all_labels.append(target.cpu().detach().numpy())\n",
    "    all_pred = np.concatenate(all_pred).ravel()\n",
    "    all_pred_raw = np.concatenate(all_pred_raw).ravel()\n",
    "    all_labels = np.concatenate(all_labels).ravel()\n",
    "    mcc, selectivity, recall, g_mean, balanced_acc = metrics(all_pred, all_labels)\n",
    "    val_data_frame = pd.DataFrame(\n",
    "        [{\n",
    "            'Layer': args['layer_number'],\n",
    "            'Feature': args['traits_number_str'],\n",
    "            'Round': args['current_epoch'],\n",
    "            'Model': args['model_name'],\n",
    "            'ACC': accuracy_score(all_labels, all_pred),\n",
    "            'Ave_loss': None,\n",
    "            'Top2': top2n / len(val_set),\n",
    "            'AUC': roc_auc_score(all_labels, all_pred_raw),\n",
    "            'MCC': mcc,\n",
    "            'Jaccard': jaccard_score(all_labels, all_pred),\n",
    "            'Precision': precision_score(all_labels, all_pred, zero_division=args['zero_division']),\n",
    "            'Recall': recall,\n",
    "            'F1': f1_score(all_labels, all_pred),\n",
    "            'Selectivity': selectivity,\n",
    "            'G_mean': g_mean,\n",
    "            'Balanced_acc': balanced_acc,\n",
    "        }],\n",
    "        columns=['Layer', 'Feature', 'Round', 'Model', 'ACC', 'Ave_loss', 'Top2', 'AUC', 'MCC', 'Jaccard', 'Precision', 'Recall', 'F1', 'Selectivity', 'G_mean', 'Balanced_acc'],\n",
    "        index=[0],\n",
    "    )\n",
    "    val_data_frame.to_csv(args['val_result_path'])\n",
    "    return val_data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697e756d-1c23-47be-a5cf-6f6b5d8bd2f7",
   "metadata": {},
   "source": [
    "## 3.3 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25781e5f-65d4-41bc-9cf7-f3cb84cf48e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, test_set):\n",
    "    model.eval()\n",
    "    sf = nn.Softmax(dim=1)\n",
    "    all_pred = []\n",
    "    all_pred_raw = []\n",
    "    all_labels = []\n",
    "    top2n = 0\n",
    "    with torch.no_grad():\n",
    "        for mol in test_set:\n",
    "            mol = mol.to(args['device'])\n",
    "            mol.x = mol.x.to(torch.float32)\n",
    "            mol.edge_attr = mol.edge_attr.to(torch.float32)\n",
    "            target = mol.y\n",
    "            output = model(mol)\n",
    "            # squeeze\n",
    "            output = torch.squeeze(output)\n",
    "            # tracking\n",
    "            top2n += top2(output, target)\n",
    "            all_pred.append(np.argmax(output.cpu().detach().numpy(), axis=1))\n",
    "            all_pred_raw.append(sf(output)[:, 1].cpu().detach().numpy())\n",
    "            all_labels.append(target.cpu().detach().numpy())\n",
    "    all_pred = np.concatenate(all_pred).ravel()\n",
    "    all_pred_raw = np.concatenate(all_pred_raw).ravel()\n",
    "    all_labels = np.concatenate(all_labels).ravel()\n",
    "    mcc, selectivity, recall, g_mean, balanced_acc = metrics(all_pred, all_labels)\n",
    "    test_data_frame = pd.DataFrame(\n",
    "        [{\n",
    "            'Layer': args['layer_number'],\n",
    "            'Feature': args['traits_number_str'],\n",
    "            'Round': args['current_epoch'],\n",
    "            'Model': args['model_name'],\n",
    "            'ACC': accuracy_score(all_labels, all_pred),\n",
    "            'Ave_loss': None,\n",
    "            'Top2': top2n / len(test_set),\n",
    "            'AUC': roc_auc_score(all_labels, all_pred_raw),\n",
    "            'MCC': mcc,\n",
    "            'Jaccard': jaccard_score(all_labels, all_pred),\n",
    "            'Precision': precision_score(all_labels, all_pred, zero_division=args['zero_division']),\n",
    "            'Recall': recall,\n",
    "            'F1': f1_score(all_labels, all_pred),\n",
    "            'Selectivity': selectivity,\n",
    "            'G_mean': g_mean,\n",
    "            'Balanced_acc': balanced_acc,\n",
    "        }],\n",
    "        columns=[\n",
    "            'Layer', 'Feature', 'Round', 'Model', \n",
    "            'ACC', 'Ave_loss', 'Top2', 'AUC', 'MCC', \n",
    "            'Jaccard', 'Precision', 'Recall', 'F1', \n",
    "            'Selectivity', 'G_mean', 'Balanced_acc'],\n",
    "        index=[0],\n",
    "    )\n",
    "    print(\n",
    "        f'[{test_data_frame[\"Layer\"][0]}]Layer'\n",
    "        f'[{test_data_frame[\"Feature\"][0]}]Feature'\n",
    "        f'[{test_data_frame[\"Round\"][0]}]Round'\n",
    "        f'[{test_data_frame[\"Model\"][0]}]Model\\n'\n",
    "        # f'ACC: [{test_data_frame[\"ACC\"][0]}]\\n'\n",
    "        # f'Ave_loss: [{test_data_frame[\"Ave_loss\"][0]}]\\n'\n",
    "        f'Top2 Score[{test_data_frame[\"Top2\"][0]}]'\n",
    "        # f'AUC: [{test_data_frame[\"AUC\"][0]}]\\n'\n",
    "        # f'MCC: [{test_data_frame[\"MCC\"][0]}]\\n'\n",
    "        # f'Selectivity: [{test_data_frame[\"Selectivity\"][0]}]\\n'\n",
    "        # f'Recall: [{test_data_frame[\"Recall\"][0]}]\\n'\n",
    "        # f'G_mean: [{test_data_frame[\"G_mean\"][0]}]\\n'\n",
    "        # f'Balanced_acc: [{test_data_frame[\"Balanced_acc\"][0]}]\\n'\n",
    "        # f'F1: [{test_data_frame[\"F1\"][0]}]\\n'\n",
    "        # f'Precision: [{test_data_frame[\"Precision\"][0]}]\\n'\n",
    "        # f'Jaccard: [{test_data_frame[\"Jaccard\"][0]}]'\n",
    "    )\n",
    "    test_data_frame.to_csv(args[\"test_result_path\"])\n",
    "    # print('test_data_frame = ', test_data_frame)\n",
    "\n",
    "    return test_data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7c1700-ae8d-47db-a360-4aa37b47dde6",
   "metadata": {},
   "source": [
    "# 4 Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b680fe6-414b-4631-be23-bd6bc45f2951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(\n",
    "    args, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    test_loader,\n",
    "    is_del=False,\n",
    "):\n",
    "    seed_torch(args['seed'])\n",
    "    torch.manual_seed(args['seed'])\n",
    "    new_model_dir = os.path.join(args['model_dir'], args['traits_number_str'])\n",
    "    new_result_dir = os.path.join(args['result_dir'], args['traits_number_str'])\n",
    "    if not os.path.exists(new_model_dir): os.mkdir(new_model_dir)\n",
    "    if not os.path.exists(new_result_dir): os.mkdir(new_result_dir)\n",
    "    test_result_dict = result_dict\n",
    "    test_results_path = os.path.join(\n",
    "        new_result_dir, \n",
    "        '_'+str(args['layer_number'])+args['traits_number_str']+'_test.csv')\n",
    "    new_new_model_dir = os.path.join(new_model_dir, args['model_name'])\n",
    "    new_new_result_dir = os.path.join(new_result_dir, args['model_name'])\n",
    "    val_results_dir = os.path.join(new_new_result_dir, 'valResults')\n",
    "    if not os.path.exists(new_new_model_dir): os.mkdir(new_new_model_dir)\n",
    "    if not os.path.exists(new_new_result_dir): os.mkdir(new_new_result_dir)\n",
    "    if not os.path.exists(val_results_dir): os.mkdir(val_results_dir)\n",
    "    \n",
    "    args['train_result_path'] = os.path.join(\n",
    "        new_result_dir, \n",
    "        '_'+str(args['layer_number'])+'_'+args['traits_number_str']+'_'+\n",
    "        args['model_name']+'_train.csv')\n",
    "    val_results_path = os.path.join(\n",
    "            new_new_result_dir, \n",
    "            '_'+str(args['layer_number'])+'_'+args['traits_number_str']+'_'+\n",
    "            args['model_name']+'_val.csv')\n",
    "    test_results_path_ = os.path.join(\n",
    "            new_new_result_dir, \n",
    "            '_'+str(args['layer_number'])+'_'+args['traits_number_str']+'_'+\n",
    "            args['model_name']+'_test.csv')\n",
    "    args['model_path'] = os.path.join(new_new_model_dir, '_'+args['traits_number_str']+'_'+args['model_name']+'.pt')\n",
    "    train_result_dict = result_dict\n",
    "    val_result_dict = result_dict\n",
    "    model = ALLModel(args).to(args['device'])\n",
    "    weights = torch.tensor([1, args['pos_weight']], dtype=torch.float32).to(args['device'])\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(weight=weights)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=args['lr'])\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    max_top2 = 0\n",
    "    max_number_ = 0\n",
    "    for epoch in tqdm(\n",
    "        range(1, args['epoch'] + 1), \n",
    "        total=args['epoch'], \n",
    "        desc=f'Total Progress[111/{args[\"traits_number_str\"]}]The current model[{args[\"model_name\"]}]'):\n",
    "        args['current_epoch'] = str(epoch)\n",
    "        a_train_dict = train(args, model, train_loader, optimizer, loss_fn)\n",
    "        train_result_dict = pd.concat([train_result_dict, a_train_dict]).reset_index(drop=True)\n",
    "        top2acc = val(model, args['device'], val_loader, optimizer, loss_fn)\n",
    "        scheduler.step()\n",
    "        max_number_ += 1\n",
    "        if max_number_ > args['max_number']: break\n",
    "        if top2acc > max_top2:\n",
    "            max_number_ = 0\n",
    "            max_top2 = top2acc\n",
    "            args['val_result_path'] = os.path.join(\n",
    "                val_results_dir, \n",
    "                args['model_name']+str(args['layer_number'])+args['current_epoch']+\n",
    "                '_val.csv')\n",
    "            a_val_dict = val2(args, model, val_loader, optimizer, loss_fn)\n",
    "            val_result_dict = pd.concat([val_result_dict, a_val_dict]).reset_index(drop=True)\n",
    "            torch.save(model.state_dict(), args['model_path'])\n",
    "            a_test_dict = test(args, model, test_loader)\n",
    "            test_result_dict = pd.concat([test_result_dict, a_test_dict]).reset_index(drop=True)\n",
    "            test_result_dict.to_csv(test_results_path_)\n",
    "    train_result_dict.to_csv(args['train_result_path'])\n",
    "    val_result_dict.to_csv(val_results_path)\n",
    "    model = ALLModel(args).to(args['device'])\n",
    "    model.load_state_dict(torch.load(args['model_path']))\n",
    "    a_test_dict = test(args, model, test_loader)\n",
    "    test_result_dict = pd.concat([test_result_dict, a_test_dict]).reset_index(drop=True)\n",
    "    test_result_dict.to_csv(test_results_path)\n",
    "    return test_result_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5d2b81-5265-4370-b532-f7d33a555f47",
   "metadata": {},
   "source": [
    "# 5 Entry and exit parameter settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce4a274-196b-4d18-91c1-28f99cd46aec",
   "metadata": {},
   "source": [
    "## 5.1 Parameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5398107f-36d9-4391-8ab0-1c666f4bc9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'lr': 0.01,\n",
    "    'epoch': 400,\n",
    "    'max_number': 65,\n",
    "    'current_epoch': 0,\n",
    "    'seed': RANDOM_NUMBERS,\n",
    "    'pos_weight': 3,\n",
    "    'conv_hidden': 1024,\n",
    "    'cls_hidden': 1024,\n",
    "    'layer_number': 3,\n",
    "    'max_degree': 5,\n",
    "    'traits_number': 29,\n",
    "    'zero_division': 0,\n",
    "    'traits_number_str': '111',\n",
    "    'conv': None,\n",
    "    'device': None,\n",
    "    'model_name': None,\n",
    "    'model_dir': None,\n",
    "    'model_path': None,\n",
    "    'result_dir': None,\n",
    "    'train_result_path': None,\n",
    "    'val_result_path': None,\n",
    "    'test_result_path': None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66de5eff-49ea-45b3-b1ef-76c1e40bee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import (\n",
    "    TAGConv,\n",
    "    ClusterGCNConv,\n",
    "    FiLMConv,\n",
    "    SAGEConv,\n",
    "    TransformerConv,\n",
    "    MFConv,\n",
    "    GATConv,\n",
    "    GCNConv,\n",
    "    GINConv,\n",
    ")\n",
    "ModelList = [\n",
    "    {'name': 'TAG', 'model': TAGConv},\n",
    "    {'name': 'ClusterGCN', 'model': ClusterGCNConv},\n",
    "    {'name': 'FiLM', 'model': FiLMConv},\n",
    "    {'name': 'SAGE', 'model': SAGEConv},\n",
    "    {'name': 'Transformer', 'model': TransformerConv},\n",
    "    {'name': 'MF', 'model': MFConv},\n",
    "    {'name': 'GAT', 'model': GATConv},\n",
    "    {'name': 'GCN', 'model': GCNConv},\n",
    "    {'name': 'GIN', 'model': GINConv},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d06527-1744-4707-a136-5b2d1edb7f91",
   "metadata": {},
   "source": [
    "## 5.2 Parameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "699258ea-8e11-4595-8470-50938ce6f126",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = pd.DataFrame(\n",
    "        columns=[\n",
    "            'Layer', 'Feature', 'Round', 'Model', \n",
    "            'ACC', 'Ave_loss', 'Top2', 'AUC', 'MCC', 'Jaccard', 'Precision', 'Recall', \n",
    "            'F1', 'Selectivity', 'G_mean', 'Balanced_acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4c7f4f-25d2-48c0-a9c9-c4777fafa40d",
   "metadata": {},
   "source": [
    "## 5.1 Realization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "baea10b1-2991-4079-8cea-af6b00a349f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress[111/010]The current model[MF]:   0%|          | 1/400 [00:01<10:16,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]Layer[010]Feature[1]Round[MF]Model\n",
      "Top2 Score[0.7426470588235294]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress[111/010]The current model[MF]:   0%|          | 2/400 [00:02<09:52,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]Layer[010]Feature[2]Round[MF]Model\n",
      "Top2 Score[0.75]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress[111/010]The current model[MF]:   1%|          | 4/400 [00:05<08:55,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]Layer[010]Feature[4]Round[MF]Model\n",
      "Top2 Score[0.7647058823529411]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress[111/010]The current model[MF]:   2%|▏         | 9/400 [00:11<07:56,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]Layer[010]Feature[9]Round[MF]Model\n",
      "Top2 Score[0.7573529411764706]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress[111/010]The current model[MF]:   4%|▍         | 16/400 [00:19<07:38,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]Layer[010]Feature[16]Round[MF]Model\n",
      "Top2 Score[0.7794117647058824]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress[111/010]The current model[MF]:   8%|▊         | 31/400 [00:35<07:18,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]Layer[010]Feature[31]Round[MF]Model\n",
      "Top2 Score[0.7941176470588235]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress[111/010]The current model[MF]:  24%|██▍       | 96/400 [01:48<05:42,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]Layer[010]Feature[97]Round[MF]Model\n",
      "Top2 Score[0.7941176470588235]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress[111/101]The current model[MF]:   0%|          | 1/400 [00:02<14:12,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]Layer[101]Feature[1]Round[MF]Model\n",
      "Top2 Score[0.7132352941176471]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress[111/101]The current model[MF]:   0%|          | 2/400 [00:03<11:32,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]Layer[101]Feature[2]Round[MF]Model\n",
      "Top2 Score[0.7352941176470589]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress[111/101]The current model[MF]:   1%|          | 3/400 [00:05<10:46,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]Layer[101]Feature[3]Round[MF]Model\n",
      "Top2 Score[0.7279411764705882]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress[111/101]The current model[MF]:   1%|          | 4/400 [00:06<10:17,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]Layer[101]Feature[4]Round[MF]Model\n",
      "Top2 Score[0.7573529411764706]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress[111/101]The current model[MF]:   2%|▎         | 10/400 [00:13<08:11,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]Layer[101]Feature[10]Round[MF]Model\n",
      "Top2 Score[0.7720588235294118]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress[111/101]The current model[MF]:   3%|▎         | 11/400 [00:15<08:35,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]Layer[101]Feature[11]Round[MF]Model\n",
      "Top2 Score[0.7647058823529411]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress[111/101]The current model[MF]:   3%|▎         | 13/400 [00:17<08:27,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]Layer[101]Feature[13]Round[MF]Model\n",
      "Top2 Score[0.7647058823529411]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress[111/101]The current model[MF]:   4%|▍         | 15/400 [00:20<08:57,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]Layer[101]Feature[15]Round[MF]Model\n",
      "Top2 Score[0.7647058823529411]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress[111/101]The current model[MF]:   6%|▌         | 23/400 [00:30<07:50,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]Layer[101]Feature[23]Round[MF]Model\n",
      "Top2 Score[0.7647058823529411]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress[111/101]The current model[MF]:   8%|▊         | 30/400 [00:38<07:23,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]Layer[101]Feature[30]Round[MF]Model\n",
      "Top2 Score[0.7720588235294118]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress[111/101]The current model[MF]:  24%|██▍       | 95/400 [01:50<05:55,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]Layer[101]Feature[96]Round[MF]Model\n",
      "Top2 Score[0.7720588235294118]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress[111/110]The current model[MF]:   0%|          | 1/400 [00:01<09:25,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]Layer[110]Feature[1]Round[MF]Model\n",
      "Top2 Score[0.7426470588235294]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress[111/110]The current model[MF]:   0%|          | 2/400 [00:03<10:23,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]Layer[110]Feature[2]Round[MF]Model\n",
      "Top2 Score[0.7573529411764706]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress[111/110]The current model[MF]:   1%|          | 4/400 [00:05<09:07,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]Layer[110]Feature[4]Round[MF]Model\n",
      "Top2 Score[0.7794117647058824]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress[111/110]The current model[MF]:   2%|▏         | 6/400 [00:08<08:43,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]Layer[110]Feature[6]Round[MF]Model\n",
      "Top2 Score[0.7941176470588235]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress[111/110]The current model[MF]:   2%|▎         | 10/400 [00:12<08:01,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]Layer[110]Feature[10]Round[MF]Model\n",
      "Top2 Score[0.7941176470588235]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress[111/110]The current model[MF]:   4%|▎         | 14/400 [00:17<07:48,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]Layer[110]Feature[14]Round[MF]Model\n",
      "Top2 Score[0.7794117647058824]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress[111/110]The current model[MF]:   4%|▍         | 15/400 [00:18<08:11,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]Layer[110]Feature[15]Round[MF]Model\n",
      "Top2 Score[0.7794117647058824]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress[111/110]The current model[MF]:   5%|▌         | 21/400 [00:25<07:43,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]Layer[110]Feature[21]Round[MF]Model\n",
      "Top2 Score[0.7794117647058824]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress[111/110]The current model[MF]:   8%|▊         | 31/400 [00:36<07:23,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]Layer[110]Feature[31]Round[MF]Model\n",
      "Top2 Score[0.7720588235294118]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress[111/110]The current model[MF]:  24%|██▍       | 96/400 [01:48<05:43,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]Layer[110]Feature[97]Round[MF]Model\n",
      "Top2 Score[0.7720588235294118]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress[111/010]The current model[MF]:   0%|          | 1/400 [00:02<17:08,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]Layer[010]Feature[1]Round[MF]Model\n",
      "Top2 Score[0.7426470588235294]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress[111/010]The current model[MF]:   1%|          | 4/400 [00:09<16:33,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]Layer[010]Feature[4]Round[MF]Model\n",
      "Top2 Score[0.8014705882352942]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress[111/010]The current model[MF]:   1%|▏         | 5/400 [00:12<16:06,  2.45s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m     trainLoader, valLoader, testLoader \u001b[38;5;241m=\u001b[39m get_loader_data(trainData, testData, batchSize)\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# main\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     DataFrameSet \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainLoader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalLoader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestLoader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_del\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     all_test_dict \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([all_test_dict, DataFrameSet])\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     45\u001b[0m all_test_dict\u001b[38;5;241m.\u001b[39mto_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(newGnnResultsDir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mALL_results[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mLayer].csv\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "Cell \u001b[0;32mIn[12], line 52\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(args, train_loader, val_loader, test_loader, is_del)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \n\u001b[1;32m     49\u001b[0m     total\u001b[38;5;241m=\u001b[39margs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     50\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal Progress[111/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraits_number_str\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]The current model[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     51\u001b[0m     args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(epoch)\n\u001b[0;32m---> 52\u001b[0m     a_train_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     train_result_dict \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([train_result_dict, a_train_dict])\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     54\u001b[0m     top2acc \u001b[38;5;241m=\u001b[39m val(model, args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m], val_loader, optimizer, loss_fn)\n",
      "Cell \u001b[0;32mIn[9], line 16\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(args, model, training_set, optimizer, criterion)\u001b[0m\n\u001b[1;32m     13\u001b[0m target \u001b[38;5;241m=\u001b[39m mol\u001b[38;5;241m.\u001b[39my\n\u001b[1;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 16\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[1;32m     18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/DATA/GTDATA/envs/linux/Protein/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DATA/GTDATA/envs/linux/Protein/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 40\u001b[0m, in \u001b[0;36mALLModel.forward\u001b[0;34m(self, mol)\u001b[0m\n\u001b[1;32m     38\u001b[0m res \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_number):\n\u001b[0;32m---> 40\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear1(res)\n\u001b[1;32m     43\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(res)\n",
      "File \u001b[0;32m~/DATA/GTDATA/envs/linux/Protein/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DATA/GTDATA/envs/linux/Protein/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/DATA/GTDATA/envs/linux/Protein/lib/python3.8/site-packages/torch_geometric/nn/conv/mf_conv.py:105\u001b[0m, in \u001b[0;36mMFConv.forward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m    103\u001b[0m out \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mnew_empty(\u001b[38;5;28mlist\u001b[39m(h\u001b[38;5;241m.\u001b[39msize())[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_channels])\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (lin_l, lin_r) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlins_l, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlins_r)):\n\u001b[0;32m--> 105\u001b[0m     idx \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mdeg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    106\u001b[0m     r \u001b[38;5;241m=\u001b[39m lin_l(h\u001b[38;5;241m.\u001b[39mindex_select(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim, idx))\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x_r \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_test_dict = result_dict\n",
    "args['device'] = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# args['device'] = torch.device('cpu')\n",
    "saveDir = '../data/CharacteristicAblation'\n",
    "if not os.path.exists(saveDir): os.mkdir(saveDir)\n",
    "saveModelsDir = os.path.join(saveDir, 'Models')\n",
    "gnnResultsDir = os.path.join(saveDir, 'Results')\n",
    "if not os.path.exists(saveModelsDir): os.mkdir(saveModelsDir)\n",
    "if not os.path.exists(gnnResultsDir): os.mkdir(gnnResultsDir)\n",
    "args['model_dir'] = saveModelsDir\n",
    "args['result_dir'] = gnnResultsDir\n",
    "args['conv'] = MFConv\n",
    "args['model_name'] = 'MF'\n",
    "layer_number = 5\n",
    "for layer in range(1, layer_number+1):\n",
    "    args['layer_number'] = layer\n",
    "    newSaveModelsDir = os.path.join(saveModelsDir, f'{layer}Layer')\n",
    "    newGnnResultsDir = os.path.join(gnnResultsDir, f'{layer}Layer')\n",
    "    if not os.path.exists(newSaveModelsDir): os.mkdir(newSaveModelsDir)\n",
    "    if not os.path.exists(newGnnResultsDir): os.mkdir(newGnnResultsDir)\n",
    "    args['model_dir'] = newSaveModelsDir\n",
    "    args['result_dir'] = newGnnResultsDir\n",
    "    for i in range(1, 8):\n",
    "        if i == 0: continue\n",
    "        if i == 1: continue\n",
    "        if i == 3: continue\n",
    "        if i == 4: continue\n",
    "        if i == 7: continue\n",
    "        bin_ = bin(i)[2:]\n",
    "        binNumber = bin_.zfill(3)\n",
    "        traits_ = ''.join(binNumber)\n",
    "        args['traits_number_str'] = traits_\n",
    "        trainData = train_data_list[traits_]    \n",
    "        testData = test_data_list[traits_]\n",
    "        args['traits_number'] = testData[0].x.shape[1]\n",
    "        training_set, validation_set = random_split(\n",
    "            trainData, \n",
    "            [int(len(trainData) * 0.85), len(trainData) - int(len(trainData) * 0.85)], \n",
    "            generator=torch.Generator().manual_seed(args['seed']))\n",
    "        # trainLoader, valLoader, testLoader = get_loader_data(train_data, test_data, batchSize)\n",
    "        trainLoader, valLoader, testLoader = get_loader_data(trainData, testData, batchSize)\n",
    "        # Main function\n",
    "        DataFrameSet = main(args, trainLoader, valLoader, testLoader, is_del=True)\n",
    "        all_test_dict = pd.concat([all_test_dict, DataFrameSet]).reset_index(drop=True)\n",
    "    all_test_dict.to_csv(os.path.join(newGnnResultsDir, f'ALL_results[{layer}Layer].csv'))\n",
    "all_test_dict.to_csv(os.path.join(gnnResultsDir, 'ALL_results.csv'))\n",
    "print('End')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
