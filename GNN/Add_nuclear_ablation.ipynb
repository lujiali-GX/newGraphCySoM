{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1b1d257-2cbb-4c01-b067-aafa08033571",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "import torch\n",
    "from torch_geometric.data import Dataset, Data, DataLoader\n",
    "from torch_geometric import loader\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import torch.nn as nn\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, ReLU\n",
    "import torch.nn.functional as F\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.nn import GATConv, GCNConv, GINConv, MFConv, SAGEConv\n",
    "from torch_geometric.nn import global_add_pool\n",
    "from torch.utils.data import random_split\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.utils import from_networkx\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, accuracy_score, precision_score, f1_score, recall_score, jaccard_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d68a033-cd49-4735-b5bb-d39976276e0d",
   "metadata": {},
   "source": [
    "# 0 DataProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e98369-9c42-42dc-a0fc-e95fc9d1ea4b",
   "metadata": {},
   "source": [
    "## 0.1 Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48f79b4d-f95f-4609-96e2-6428bf9e428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datapath = '../data/train_datsets.pkl'\n",
    "test_datapath = '../data/test_datsets.pkl'\n",
    "fr = open(train_datapath, 'rb')\n",
    "train_data = pickle.load(fr)\n",
    "fe = open(test_datapath, 'rb')\n",
    "test_data = pickle.load(fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57f89a7-2614-4d38-8ed9-19a1a806792d",
   "metadata": {},
   "source": [
    "## 0.2 Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ff25af0-e728-471d-b318-4987c8997c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_list = {}\n",
    "test_data_list = {}\n",
    "for i in range(1, 9):\n",
    "    binNumber = bin(i)[2:].zfill(3)\n",
    "    traits_ = ''.join(binNumber)\n",
    "    new_train_data = []\n",
    "    new_test_data = []\n",
    "    for index, train_ in enumerate(train_data):\n",
    "        # Initialize data_ as an empty tensor\n",
    "        train_data_ = None\n",
    "        train_x_10 = train_.x[:, :10]\n",
    "        train_x_16 = train_.x[:, 10:26]\n",
    "        train_x_3 = train_.x[:, 26:]\n",
    "        if traits_[0] == '1':\n",
    "            train_data_ = train_x_10\n",
    "        if traits_[1] == '1':\n",
    "            train_data_ = torch.cat((train_data_, train_x_16), dim=1) if train_data_ is not None else train_x_16 \n",
    "        if traits_[2] == '1':\n",
    "            train_data_ = torch.cat((train_data_, train_x_3), dim=1) if train_data_ is not None else train_x_3\n",
    "        new_data_ = Data(\n",
    "            x=train_data_,\n",
    "            edge_index=train_.edge_index,\n",
    "            edge_attr=train_.edge_attr,\n",
    "            y=train_.y,\n",
    "            target=train_.target,\n",
    "            name=train_.name,\n",
    "            n_index=train_.n_index,\n",
    "            subgraph_node1=train_.subgraph_node1,\n",
    "            subgraph_node2=train_.subgraph_node2\n",
    "        )\n",
    "        new_train_data.append(new_data_)\n",
    "    train_data_list[traits_] = new_train_data\n",
    "    for test_ in test_data:\n",
    "        # Initialize data_ as an empty tensor\n",
    "        test_data_ = None\n",
    "        test_x_10 = test_.x[:, :10]\n",
    "        test_x_16 = test_.x[:, 10:26]\n",
    "        test_x_3 = test_.x[:, 26:]\n",
    "        if traits_[0] == '1':\n",
    "            test_data_ = test_x_10\n",
    "        if traits_[1] == '1':\n",
    "            test_data_ = torch.cat((test_data_, test_x_16), dim=1) if test_data_ is not None else test_x_16 \n",
    "        if traits_[2] == '1':\n",
    "            test_data_ = torch.cat((test_data_, test_x_3), dim=1) if test_data_ is not None != 0 else test_x_3 \n",
    "        new_data_ = Data(\n",
    "            x=test_data_,\n",
    "            edge_index=test_.edge_index,\n",
    "            edge_attr=test_.edge_attr,\n",
    "            y=test_.y,\n",
    "            target=test_.target,\n",
    "            name=test_.name,\n",
    "            n_index=test_.n_index,\n",
    "            subgraph_node1=test_.subgraph_node1,\n",
    "            subgraph_node2=test_.subgraph_node2\n",
    "        )\n",
    "        new_test_data.append(new_data_)\n",
    "    test_data_list[traits_] = new_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a9bbba-c943-4ee9-a2b8-acc10840acd1",
   "metadata": {},
   "source": [
    "## 0.3 Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b6ff1ef-8486-47ad-9544-f59ce5acf83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader_data(train_data, test_data, batch_size):\n",
    "    training_set, validation_set = random_split(train_data, [int(len(train_data) * 0.85), len(train_data) - int(len(train_data) * 0.85)], generator=torch.Generator().manual_seed(12345))\n",
    "    train_loader = loader.DataLoader(training_set, batch_size, shuffle=True)\n",
    "    val_loader = loader.DataLoader(validation_set, batch_size, shuffle=True)\n",
    "    test_loader = loader.DataLoader(test_data, batch_size, shuffle=False)\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53102d6-b39d-4294-bce7-0a51672aa82c",
   "metadata": {},
   "source": [
    "## 0.4 Set constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "011e3dc0-288c-466e-b952-c1b95b6e20bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_NUMBERS = 12345 # Random numbers\n",
    "batchSize = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a861549-e3dc-4549-a36d-15a4ec9a53e2",
   "metadata": {},
   "source": [
    "## 0.5 Set a random number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e1d1eb9-2c34-4f9a-a1da-c95b800cb526",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.inf)\n",
    "def seed_torch(seed=RANDOM_NUMBERS):\n",
    "    # Seeding ensures that the same random number \n",
    "    # is generated every time you run the code.\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) \n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f617e261-8234-4c14-9a73-95c9c093b148",
   "metadata": {},
   "source": [
    "# 1 Set up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba157222-5ed6-40e5-af28-b48b566290ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALLModel(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(ALLModel, self).__init__()\n",
    "        self.way = args['way']\n",
    "        num_classes = 2\n",
    "\n",
    "        conv_hidden = args['conv_hidden']\n",
    "        traits_number = args['traits_number']\n",
    "        cls_hidden = args['cls_hidden']\n",
    "        self.layer_number = args['layer_number']\n",
    "        self.device = args['device']\n",
    "        self.conv = nn.ModuleList()\n",
    "        if args['model_name'] != 'GIN':\n",
    "            for i in range(self.layer_number):\n",
    "                if i == 0:\n",
    "                    self.conv.append(args['conv'](traits_number, conv_hidden))\n",
    "                else:\n",
    "                    self.conv.append(args['conv'](conv_hidden, conv_hidden))\n",
    "        else:\n",
    "            from torch.nn import Sequential as Seq, Linear as Lin, ReLU\n",
    "            for i in range(self.layer_number):\n",
    "                if i == 0:\n",
    "                    nn_ = Seq(Lin(traits_number, conv_hidden), ReLU(), Lin(conv_hidden, conv_hidden))\n",
    "                    self.conv.append(args['conv'](nn_))\n",
    "                else:\n",
    "                    nn_ = Seq(Lin(conv_hidden, conv_hidden), ReLU(), Lin(conv_hidden, conv_hidden))\n",
    "                    self.conv.append(args['conv'](nn_))\n",
    "\n",
    "        self.conv = self.conv.to(self.device)\n",
    "        \n",
    "        if self.way=='concate': \n",
    "            self.linear1 = nn.Linear(conv_hidden*2, cls_hidden)\n",
    "        else:\n",
    "            self.linear1 = nn.Linear(conv_hidden, cls_hidden)\n",
    "        self.linear2 = nn.Linear(cls_hidden, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drop1 = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, mol):\n",
    "        x = mol.x.to(self.device)\n",
    "        edge_index = mol.edge_index.to(self.device)\n",
    "        res = x\n",
    "        for i in range(self.layer_number):\n",
    "            res = self.conv[i](res, edge_index)\n",
    "            if i == 1: r1 = res\n",
    "        if self.way=='mean':\n",
    "            res = r1 + res\n",
    "            res = res / 2\n",
    "        elif self.way=='max':\n",
    "            res = torch.max(r1, res)\n",
    "        elif self.way=='min':\n",
    "            res = torch.min(r1, res)\n",
    "        elif self.way=='addition':\n",
    "            res = r1 + res\n",
    "        elif self.way=='concate':\n",
    "            res = torch.cat((r1, res), dim=1)\n",
    "        \n",
    "        res = self.linear1(res)\n",
    "        res = self.relu(res)\n",
    "        res = self.drop1(res)\n",
    "        res = self.linear2(res)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff8e8fa-9d90-4297-9fa9-0deca444ac45",
   "metadata": {},
   "source": [
    "# 2 Set up evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62783958-fe1c-4dd6-a004-c64a48802f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top2(output, label):\n",
    "    sf = nn.Softmax(dim=1)\n",
    "    preds = sf(output)\n",
    "    preds = preds[:, 1]\n",
    "    _, indices = torch.topk(preds, 2)\n",
    "    pos_index = []\n",
    "    for i in range(label.shape[0]):\n",
    "        if label[i] == 1:\n",
    "            pos_index.append(i)  \n",
    "    for li in pos_index:\n",
    "        if li in indices:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def MCC(output, label):\n",
    "    tn,fp,fn,tp=confusion_matrix(label, output).ravel()\n",
    "    up = (tp * tn) - (fp * fn)\n",
    "    down = ((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)) ** 0.5\n",
    "    if down == 0: down = 1e-10\n",
    "    return up / down\n",
    "\n",
    "def metrics(output, label):\n",
    "    tn,fp,fn,tp=confusion_matrix(label, output).ravel()\n",
    "    up = (tp * tn) - (fp * fn)\n",
    "    down = ((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)) ** 0.5\n",
    "    if down == 0: down = 1e-10\n",
    "    mcc = up / down\n",
    "    selectivity = tn / (tn + fp + 1e-10)\n",
    "    recall = tp / (tp + fn + 1e-10)\n",
    "    g_mean = (selectivity * recall) ** 0.5\n",
    "    balancedAccuracy = (recall + selectivity) / 2\n",
    "    return mcc, selectivity, recall, g_mean, balancedAccuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dddefec-c06d-4b61-af5a-d2b40e1217ac",
   "metadata": {},
   "source": [
    "# 3 Model manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0c14f1-8725-447e-a398-0ecbcda6d88e",
   "metadata": {},
   "source": [
    "## 3.1 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd3ff710-081a-4a8f-bbc4-eab21db72093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, training_set, optimizer, criterion):\n",
    "    model.train()\n",
    "    sf = nn.Softmax(dim=1)\n",
    "    total_loss = 0\n",
    "    all_pred = []\n",
    "    all_pred_raw = []\n",
    "    all_labels = []\n",
    "    top2n = 0\n",
    "    model = model.to(args['device'])\n",
    "    for mol in training_set:\n",
    "        mol = mol.to(args['device'])\n",
    "        mol.x = mol.x.to(torch.float32)\n",
    "        target = mol.y\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(mol)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # tracking\n",
    "        top2n += top2(output, target)\n",
    "        all_pred.append(np.argmax(output.cpu().detach().numpy(), axis=1))\n",
    "        all_pred_raw.append(sf(output)[:, 1].cpu().detach().numpy())\n",
    "        all_labels.append(target.cpu().detach().numpy())\n",
    "\n",
    "    all_pred = np.concatenate(all_pred).ravel()\n",
    "    all_pred_raw = np.concatenate(all_pred_raw).ravel()\n",
    "    all_labels = np.concatenate(all_labels).ravel()\n",
    "    mcc, selectivity, recall, g_mean, balanced_acc = metrics(all_pred, all_labels)\n",
    "    train_data_frame = pd.DataFrame(\n",
    "        [{\n",
    "            'NucleationMethod': args['way'],\n",
    "            'Layer': args['layer_number'],\n",
    "            'Feature': args['traits_number_str'],\n",
    "            'Round': args['current_epoch'],\n",
    "            'Model': args['model_name'],\n",
    "            'ACC': accuracy_score(all_labels, all_pred),\n",
    "            'Ave_loss': total_loss / len(training_set),\n",
    "            'Top2': top2n / len(training_set),\n",
    "            'AUC': roc_auc_score(all_labels, all_pred_raw),\n",
    "            'MCC': mcc,\n",
    "            'Jaccard': jaccard_score(all_labels, all_pred),\n",
    "            'Precision': precision_score(all_labels, all_pred, zero_division=args['zero_division']),\n",
    "            'Recall': recall,\n",
    "            'F1': f1_score(all_labels, all_pred),\n",
    "            'Selectivity': selectivity,\n",
    "            'G_mean': g_mean,\n",
    "            'Balanced_acc': balanced_acc,\n",
    "        }],\n",
    "        columns=['NucleationMethod','Layer', 'Feature', 'Round', 'Model', 'ACC', 'Ave_loss', 'Top2', 'AUC', 'MCC', 'Jaccard', 'Precision', 'Recall', 'F1', 'Selectivity', 'G_mean', 'Balanced_acc'],\n",
    "        index=[0],\n",
    "    )\n",
    "    # train_data_frame.to_csv(args['train_result_path'])\n",
    "    return train_data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7547be90-b20d-40ea-a070-4346d08fd701",
   "metadata": {},
   "source": [
    "## 3.2 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b8c9a04-4c0b-4fca-bbaf-a12bcd00ec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model, device, val_set, optimizer, criterion):\n",
    "    model.eval()\n",
    "    sf = nn.Softmax(dim=1)\n",
    "    top2n = 0\n",
    "    for mol in val_set:\n",
    "        mol = mol.to(device)\n",
    "        mol.x = mol.x.to(torch.float32)\n",
    "        target = mol.y\n",
    "        optimizer.zero_grad()\n",
    "        output = model(mol).to(device)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # tracking\n",
    "        top2n += top2(output, target)\n",
    "    return top2n / len(val_set)\n",
    "\n",
    "def val2(\n",
    "    args,\n",
    "    model,\n",
    "    val_set, \n",
    "    optimizer, \n",
    "    criterion,\n",
    "):\n",
    "    model.eval()\n",
    "    sf = nn.Softmax(dim=1)\n",
    "    total_loss = 0\n",
    "    all_pred = []\n",
    "    all_pred_raw = []\n",
    "    all_labels = []\n",
    "    top2n = 0\n",
    "    for mol in val_set:\n",
    "        mol = mol.to(args['device'])\n",
    "        mol.x = mol.x.to(torch.float32)\n",
    "        target = mol.y\n",
    "        optimizer.zero_grad()\n",
    "        output = model(mol)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        # tracking\n",
    "        top2n += top2(output, target)\n",
    "        all_pred.append(np.argmax(output.cpu().detach().numpy(), axis=1))\n",
    "        all_pred_raw.append(sf(output)[:, 1].cpu().detach().numpy())\n",
    "        all_labels.append(target.cpu().detach().numpy())\n",
    "    all_pred = np.concatenate(all_pred).ravel()\n",
    "    all_pred_raw = np.concatenate(all_pred_raw).ravel()\n",
    "    all_labels = np.concatenate(all_labels).ravel()\n",
    "    mcc, selectivity, recall, g_mean, balanced_acc = metrics(all_pred, all_labels)\n",
    "    val_data_frame = pd.DataFrame(\n",
    "        [{\n",
    "            'NucleationMethod': args['way'],\n",
    "            'Layer': args['layer_number'],\n",
    "            'Feature': args['traits_number_str'],\n",
    "            'Round': args['current_epoch'],\n",
    "            'Model': args['model_name'],\n",
    "            'ACC': accuracy_score(all_labels, all_pred),\n",
    "            'Ave_loss': None,\n",
    "            'Top2': top2n / len(val_set),\n",
    "            'AUC': roc_auc_score(all_labels, all_pred_raw),\n",
    "            'MCC': mcc,\n",
    "            'Jaccard': jaccard_score(all_labels, all_pred),\n",
    "            'Precision': precision_score(all_labels, all_pred, zero_division=args['zero_division']),\n",
    "            'Recall': recall,\n",
    "            'F1': f1_score(all_labels, all_pred),\n",
    "            'Selectivity': selectivity,\n",
    "            'G_mean': g_mean,\n",
    "            'Balanced_acc': balanced_acc,\n",
    "        }],\n",
    "        columns=['NucleationMethod','Layer', 'Feature', 'Round', 'Model', 'ACC', 'Ave_loss', 'Top2', 'AUC', 'MCC', 'Jaccard', 'Precision', 'Recall', 'F1', 'Selectivity', 'G_mean', 'Balanced_acc'],\n",
    "        index=[0],\n",
    "    )\n",
    "    val_data_frame.to_csv(args['val_result_path'])\n",
    "    return val_data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697e756d-1c23-47be-a5cf-6f6b5d8bd2f7",
   "metadata": {},
   "source": [
    "## 3.3 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25781e5f-65d4-41bc-9cf7-f3cb84cf48e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, test_set):\n",
    "    model.eval()\n",
    "    sf = nn.Softmax(dim=1)\n",
    "    all_pred = []\n",
    "    all_pred_raw = []\n",
    "    all_labels = []\n",
    "    top2n = 0\n",
    "    with torch.no_grad():\n",
    "        for mol in test_set:\n",
    "            mol = mol.to(args['device'])\n",
    "            mol.x = mol.x.to(torch.float32)\n",
    "            mol.edge_attr = mol.edge_attr.to(torch.float32)\n",
    "            target = mol.y\n",
    "            output = model(mol)\n",
    "            # squeeze\n",
    "            output = torch.squeeze(output)\n",
    "            # tracking\n",
    "            top2n += top2(output, target)\n",
    "            all_pred.append(np.argmax(output.cpu().detach().numpy(), axis=1))\n",
    "            all_pred_raw.append(sf(output)[:, 1].cpu().detach().numpy())\n",
    "            all_labels.append(target.cpu().detach().numpy())\n",
    "    all_pred = np.concatenate(all_pred).ravel()\n",
    "    all_pred_raw = np.concatenate(all_pred_raw).ravel()\n",
    "    all_labels = np.concatenate(all_labels).ravel()\n",
    "    mcc, selectivity, recall, g_mean, balanced_acc = metrics(all_pred, all_labels)\n",
    "    test_data_frame = pd.DataFrame(\n",
    "        [{\n",
    "            'NucleationMethod': args['way'],\n",
    "            'Layer': args['layer_number'],\n",
    "            'Feature': args['traits_number_str'],\n",
    "            'Round': args['current_epoch'],\n",
    "            'Model': args['model_name'],\n",
    "            'ACC': accuracy_score(all_labels, all_pred),\n",
    "            'Ave_loss': None,\n",
    "            'Top2': top2n / len(test_set),\n",
    "            'AUC': roc_auc_score(all_labels, all_pred_raw),\n",
    "            'MCC': mcc,\n",
    "            'Jaccard': jaccard_score(all_labels, all_pred),\n",
    "            'Precision': precision_score(all_labels, all_pred, zero_division=args['zero_division']),\n",
    "            'Recall': recall,\n",
    "            'F1': f1_score(all_labels, all_pred),\n",
    "            'Selectivity': selectivity,\n",
    "            'G_mean': g_mean,\n",
    "            'Balanced_acc': balanced_acc,\n",
    "        }],\n",
    "        columns=[\n",
    "            'NucleationMethod','Layer', 'Feature', 'Round', 'Model', \n",
    "            'ACC', 'Ave_loss', 'Top2', 'AUC', 'MCC', \n",
    "            'Jaccard', 'Precision', 'Recall', 'F1', \n",
    "            'Selectivity', 'G_mean', 'Balanced_acc'],\n",
    "        index=[0],\n",
    "    )\n",
    "    print(\n",
    "        f'NucleationMethod[{test_data_frame[\"NucleationMethod\"][0]}]'\n",
    "        f'[{test_data_frame[\"Layer\"][0]}]Layer'\n",
    "        f'[{test_data_frame[\"Feature\"][0]}]Feature'\n",
    "        f'[{test_data_frame[\"Round\"][0]}]Round'\n",
    "        f'[{test_data_frame[\"Model\"][0]}]Model\\n'\n",
    "        # f'ACC: [{test_data_frame[\"ACC\"][0]}]\\n'\n",
    "        # f'Ave_loss: [{test_data_frame[\"Ave_loss\"][0]}]\\n'\n",
    "        f'Top2 Score[{test_data_frame[\"Top2\"][0]}]'\n",
    "        # f'AUC: [{test_data_frame[\"AUC\"][0]}]\\n'\n",
    "        # f'MCC: [{test_data_frame[\"MCC\"][0]}]\\n'\n",
    "        # f'Selectivity: [{test_data_frame[\"Selectivity\"][0]}]\\n'\n",
    "        # f'Recall: [{test_data_frame[\"Recall\"][0]}]\\n'\n",
    "        # f'G_mean: [{test_data_frame[\"G_mean\"][0]}]\\n'\n",
    "        # f'Balanced_acc: [{test_data_frame[\"Balanced_acc\"][0]}]\\n'\n",
    "        # f'F1: [{test_data_frame[\"F1\"][0]}]\\n'\n",
    "        # f'Precision: [{test_data_frame[\"Precision\"][0]}]\\n'\n",
    "        # f'Jaccard: [{test_data_frame[\"Jaccard\"][0]}]'\n",
    "    )\n",
    "    test_data_frame.to_csv(args[\"test_result_path\"])\n",
    "    # print('test_data_frame = ', test_data_frame)\n",
    "\n",
    "    return test_data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7c1700-ae8d-47db-a360-4aa37b47dde6",
   "metadata": {},
   "source": [
    "# 4 Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b680fe6-414b-4631-be23-bd6bc45f2951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(\n",
    "    args, \n",
    "    model_list, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    test_loader,\n",
    "    is_del=False,\n",
    "):\n",
    "    seed_torch(args['seed'])\n",
    "    torch.manual_seed(args['seed'])\n",
    "    new_model_dir = args['model_dir']\n",
    "    new_result_dir = args['result_dir']\n",
    "    test_result_dict = result_dict\n",
    "    test_results_path = os.path.join(\n",
    "        new_result_dir, \n",
    "        '_'+str(args['layer_number'])+args['traits_number_str']+'_test.csv')\n",
    "    for index0, Model in enumerate(model_list):\n",
    "        args['conv'] = Model[\"model\"]\n",
    "        args['model_name'] = Model[\"name\"]\n",
    "        new_new_model_dir = os.path.join(new_model_dir, args['model_name'])\n",
    "        new_new_result_dir = os.path.join(new_result_dir, args['model_name'])\n",
    "        # train_results_dir = os.path.join(new_new_result_dir, 'trainResults')\n",
    "        val_results_dir = os.path.join(new_new_result_dir, 'valResults')\n",
    "        if not os.path.exists(new_new_model_dir): os.mkdir(new_new_model_dir)\n",
    "        if not os.path.exists(new_new_result_dir): os.mkdir(new_new_result_dir)\n",
    "        # if not os.path.exists(train_results_dir): os.mkdir(train_results_dir)\n",
    "        if not os.path.exists(val_results_dir): os.mkdir(val_results_dir)\n",
    "        args['train_result_path'] = os.path.join(\n",
    "                new_result_dir, \n",
    "                '_'+str(args['layer_number'])+'_'+args['traits_number_str']+'_'+\n",
    "                args['model_name']+'_train.csv')\n",
    "        val_results_path = os.path.join(\n",
    "                new_new_result_dir, \n",
    "                '_'+str(args['layer_number'])+'_'+args['traits_number_str']+'_'+\n",
    "                args['model_name']+'_val.csv')\n",
    "        args['model_path'] = os.path.join(new_new_model_dir, '_'+args['traits_number_str']+'_'+args['model_name']+'.pt')\n",
    "        train_result_dict = result_dict\n",
    "        val_result_dict = result_dict\n",
    "        # model = Model[\"model\"](args).to(args['device'])\n",
    "        model = ALLModel(args).to(args['device'])\n",
    "        weights = torch.tensor([1, args['pos_weight']], dtype=torch.float32).to(args['device'])\n",
    "        loss_fn = torch.nn.CrossEntropyLoss(weight=weights)\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=args['lr'])\n",
    "        scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "        max_top2 = 0\n",
    "        max_number_ = 0\n",
    "        for epoch in tqdm(\n",
    "            range(1, args['epoch'] + 1), \n",
    "            total=args['epoch'], \n",
    "            desc=f'NucleationMethod[{args[\"way\"]}]The current model[{Model[\"name\"]}]Current characteristics[111/{args[\"traits_number_str\"]}]'):\n",
    "            args['current_epoch'] = str(epoch)\n",
    "            a_train_dict = train(args, model, train_loader, optimizer, loss_fn)\n",
    "            train_result_dict = pd.concat([train_result_dict, a_train_dict]).reset_index(drop=True)\n",
    "            top2acc = val(model, args['device'], val_loader, optimizer, loss_fn)\n",
    "            scheduler.step()\n",
    "            max_number_ += 1\n",
    "            if max_number_ > args['max_number']: break\n",
    "            if top2acc > max_top2:\n",
    "                max_number_ = 0\n",
    "                max_top2 = top2acc\n",
    "                args['val_result_path'] = os.path.join(\n",
    "                    val_results_dir, \n",
    "                    args['model_name']+str(args['layer_number'])+args['current_epoch']+\n",
    "                    '_val.csv')\n",
    "                a_val_dict = val2(args, model, val_loader, optimizer, loss_fn)\n",
    "                val_result_dict = pd.concat([val_result_dict, a_val_dict]).reset_index(drop=True)\n",
    "                torch.save(model.state_dict(), args['model_path'])\n",
    "                # print(f'Save the model turn[{epoch}]\\tTop2 Score[{max_top2}]\\n')\n",
    "        train_result_dict.to_csv(args['train_result_path'])\n",
    "        val_result_dict.to_csv(val_results_path)\n",
    "        model = ALLModel(args).to(args['device'])\n",
    "        model.load_state_dict(torch.load(args['model_path']))\n",
    "        a_test_dict = test(args, model, test_loader)\n",
    "        test_result_dict = pd.concat([test_result_dict, a_test_dict]).reset_index(drop=True)\n",
    "    test_result_dict.to_csv(test_results_path)\n",
    "    return test_result_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5d2b81-5265-4370-b532-f7d33a555f47",
   "metadata": {},
   "source": [
    "# 5 Entry and exit parameter settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce4a274-196b-4d18-91c1-28f99cd46aec",
   "metadata": {},
   "source": [
    "## 5.1 Parameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5398107f-36d9-4391-8ab0-1c666f4bc9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'lr': 0.01,\n",
    "    'epoch': 400,\n",
    "    'max_number': 65,\n",
    "    'current_epoch': 0,\n",
    "    'seed': RANDOM_NUMBERS,\n",
    "    'pos_weight': 3,\n",
    "    'conv_hidden': 1024,\n",
    "    'cls_hidden': 1024,\n",
    "    'layer_number': 3,\n",
    "    'max_degree': 5,\n",
    "    'traits_number': 29,\n",
    "    'zero_division': 0,\n",
    "    'traits_number_str': '111',\n",
    "    'way': None,\n",
    "    'conv': None,\n",
    "    'device': None,\n",
    "    'model_name': None,\n",
    "    'model_dir': None,\n",
    "    'model_path': None,\n",
    "    'result_dir': None,\n",
    "    'train_result_path': None,\n",
    "    'val_result_path': None,\n",
    "    'test_result_path': None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66de5eff-49ea-45b3-b1ef-76c1e40bee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import (\n",
    "    TAGConv,\n",
    "    ClusterGCNConv,\n",
    "    FiLMConv,\n",
    "    SAGEConv,\n",
    "    TransformerConv,\n",
    "    MFConv,\n",
    "    GATConv,\n",
    "    GCNConv,\n",
    "    GINConv,\n",
    ")\n",
    "ModelList = [\n",
    "    # {'name': 'TAG', 'model': TAGConv},\n",
    "    # {'name': 'ClusterGCN', 'model': ClusterGCNConv},\n",
    "    # {'name': 'FiLM', 'model': FiLMConv},\n",
    "    # {'name': 'SAGE', 'model': SAGEConv},\n",
    "    # {'name': 'Transformer', 'model': TransformerConv},\n",
    "    {'name': 'MF', 'model': MFConv},\n",
    "    # {'name': 'GAT', 'model': GATConv},\n",
    "    # {'name': 'GCN', 'model': GCNConv},\n",
    "    # {'name': 'GIN', 'model': GINConv},\n",
    "]\n",
    "wayList = [\n",
    "    'none',\n",
    "    'addition', \n",
    "    'mean', \n",
    "    'max', \n",
    "    'min', \n",
    "    'concate'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d06527-1744-4707-a136-5b2d1edb7f91",
   "metadata": {},
   "source": [
    "## 5.2 Parameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "699258ea-8e11-4595-8470-50938ce6f126",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = pd.DataFrame(\n",
    "        columns=[\n",
    "            'NucleationMethod','Layer', 'Feature', 'Round', 'Model', \n",
    "            'ACC', 'Ave_loss', 'Top2', 'AUC', 'MCC', 'Jaccard', 'Precision', 'Recall', \n",
    "            'F1', 'Selectivity', 'G_mean', 'Balanced_acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4c7f4f-25d2-48c0-a9c9-c4777fafa40d",
   "metadata": {},
   "source": [
    "## 5.1 Realization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baea10b1-2991-4079-8cea-af6b00a349f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NucleationMethod[none]The current model[MF]Current characteristics[111/001]:  30%|███       | 121/400 [06:35<15:12,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NucleationMethod[none][3]Layer[001]Feature[122]Round[MF]Model\n",
      "Top2 Score[0.8676470588235294]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NucleationMethod[addition]The current model[MF]Current characteristics[111/001]:  37%|███▋      | 148/400 [07:46<13:14,  3.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NucleationMethod[addition][3]Layer[001]Feature[149]Round[MF]Model\n",
      "Top2 Score[0.8676470588235294]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NucleationMethod[mean]The current model[MF]Current characteristics[111/001]:  35%|███▍      | 139/400 [07:12<13:31,  3.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NucleationMethod[mean][3]Layer[001]Feature[140]Round[MF]Model\n",
      "Top2 Score[0.8676470588235294]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NucleationMethod[max]The current model[MF]Current characteristics[111/001]:  37%|███▋      | 147/400 [09:23<16:09,  3.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NucleationMethod[max][3]Layer[001]Feature[148]Round[MF]Model\n",
      "Top2 Score[0.875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NucleationMethod[min]The current model[MF]Current characteristics[111/001]:  29%|██▉       | 117/400 [08:24<20:20,  4.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NucleationMethod[min][3]Layer[001]Feature[118]Round[MF]Model\n",
      "Top2 Score[0.875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NucleationMethod[concate]The current model[MF]Current characteristics[111/001]:  31%|███▏      | 125/400 [06:49<15:01,  3.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NucleationMethod[concate][3]Layer[001]Feature[126]Round[MF]Model\n",
      "Top2 Score[0.875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NucleationMethod[none]The current model[MF]Current characteristics[111/010]:  35%|███▌      | 141/400 [07:13<13:16,  3.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NucleationMethod[none][3]Layer[010]Feature[142]Round[MF]Model\n",
      "Top2 Score[0.8676470588235294]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NucleationMethod[addition]The current model[MF]Current characteristics[111/010]:  42%|████▏     | 167/400 [08:26<11:46,  3.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NucleationMethod[addition][3]Layer[010]Feature[168]Round[MF]Model\n",
      "Top2 Score[0.8529411764705882]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NucleationMethod[mean]The current model[MF]Current characteristics[111/010]:   7%|▋         | 27/400 [01:52<28:53,  4.65s/it]"
     ]
    }
   ],
   "source": [
    "all_test_dict = result_dict\n",
    "args['device'] = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "saveDir_ = '../data/Add_nuclear_ablation'\n",
    "if not os.path.exists(saveDir_): os.mkdir(saveDir_)\n",
    "saveModelsDir = os.path.join(saveDir_, 'Models')\n",
    "gnnResultsDir = os.path.join(saveDir_, 'Results')\n",
    "if not os.path.exists(saveModelsDir): os.mkdir(saveModelsDir)\n",
    "if not os.path.exists(gnnResultsDir): os.mkdir(gnnResultsDir)\n",
    "# args['model_dir'] = saveModelsDir\n",
    "# args['result_dir'] = gnnResultsDir\n",
    "for i in range(1, 8):\n",
    "    bin_ = bin(i)[2:]\n",
    "    binNumber = bin_.zfill(3)\n",
    "    traits_ = ''.join(binNumber)\n",
    "    args['traits_number_str'] = traits_\n",
    "    traitsSaveModelsDir = os.path.join(saveModelsDir, traits_)\n",
    "    traitsGnnResultsDir = os.path.join(gnnResultsDir, traits_)\n",
    "    if not os.path.exists(traitsSaveModelsDir): os.mkdir(traitsSaveModelsDir)\n",
    "    if not os.path.exists(traitsGnnResultsDir): os.mkdir(traitsGnnResultsDir)\n",
    "    trainData = train_data_list[traits_]    \n",
    "    testData = test_data_list[traits_]\n",
    "    for way_ in wayList:\n",
    "        args['way'] = way_\n",
    "        newSaveModelsDir = os.path.join(traitsSaveModelsDir, way_)\n",
    "        newGnnResultsDir = os.path.join(traitsGnnResultsDir, way_)\n",
    "        if not os.path.exists(newSaveModelsDir): os.mkdir(newSaveModelsDir)\n",
    "        if not os.path.exists(newGnnResultsDir): os.mkdir(newGnnResultsDir)\n",
    "        args['model_dir'] = newSaveModelsDir\n",
    "        args['result_dir'] = newGnnResultsDir\n",
    "\n",
    "        args['traits_number'] = testData[0].x.shape[1]\n",
    "        training_set, validation_set = random_split(\n",
    "            trainData, \n",
    "            [int(len(trainData) * 0.85), len(trainData) - int(len(trainData) * 0.85)], \n",
    "            generator=torch.Generator().manual_seed(args['seed']))\n",
    "        # trainLoader, valLoader, testLoader = get_loader_data(train_data, test_data, batchSize)\n",
    "        trainLoader, valLoader, testLoader = get_loader_data(trainData, testData, batchSize)\n",
    "        # Main function\n",
    "        DataFrameSet = main(args, ModelList, trainLoader, valLoader, testLoader, is_del=True)\n",
    "        all_test_dict = pd.concat([all_test_dict, DataFrameSet]).reset_index(drop=True)\n",
    "    all_test_dict.to_csv(os.path.join(traitsGnnResultsDir, f'ALL_results[{traits_}features_plus_nucleus].csv'))\n",
    "all_test_dict.to_csv(os.path.join(gnnResultsDir, 'ALL_results.csv'))\n",
    "print('End')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
