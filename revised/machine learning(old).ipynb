{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fad80aaf-b803-48d0-9c32-51d5c3201761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Any\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.rdchem import HybridizationType, ChiralType\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, matthews_corrcoef\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import joblib\n",
    "import math\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "281c001f-f967-49e5-b78f-c7ec0628aa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomNumber = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d5ca983-fadf-4137-8718-d238b14b64cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_list(catalogue: str, t_l=None):\n",
    "    f_l = []\n",
    "    f_d = dict()\n",
    "    if t_l is None:\n",
    "        t_l = [\n",
    "            'xvg', 'gro', 'pdb', 'log', 'out', 'dat', 'xyz', 'csv', 'xlsx', 'xls', 'txt',\n",
    "            'png', 'jpg', 'jpeg', 'gif', 'bmp', 'tif', 'tiff', 'svg', 'psd', 'ai', 'eps',\n",
    "            'raw', 'cr2', 'nef', 'orf', 'rw2', 'arw', 'dng', 'raf', 'srw', 'sr2',\n",
    "            'tif', 'tiff', 'tif', 'tiff', 'tif', 'tiff', 'tif', 'tiff',\n",
    "        ]\n",
    "    elif isinstance(t_l, str):\n",
    "        t_l = [t_l]\n",
    "    catalogue = os.path.abspath(catalogue)\n",
    "    f_l = os.listdir(catalogue)\n",
    "    if f_l:\n",
    "        for t in t_l:\n",
    "            f_d[t] = [os.path.join(catalogue, f) for f in f_l if t in f]\n",
    "    return f_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a22d7228-5896-4364-b4b7-03bf714b2023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_dict(file_dir: str, suffix: list):\n",
    "    file_List = get_file_list(file_dir, suffix)\n",
    "    file_List = file_List['csv']\n",
    "    newDict = {\n",
    "        '001': {\n",
    "            'LR_Top2': [], 'LR_AUC': [], 'LR_MCC': [],\n",
    "            'NB_Top2': [], 'NB_AUC': [], 'NB_MCC': [],\n",
    "            'SVM_Top2': [], 'SVM_AUC': [], 'SVM_MCC': [],\n",
    "            'DT_Top2': [], 'DT_AUC': [], 'DT_MCC': [],\n",
    "            'RF_Top2': [], 'RF_AUC': [], 'RF_MCC': [],\n",
    "        },\n",
    "        '010': {\n",
    "            'LR_Top2': [], 'LR_AUC': [], 'LR_MCC': [],\n",
    "            'NB_Top2': [], 'NB_AUC': [], 'NB_MCC': [],\n",
    "            'SVM_Top2': [], 'SVM_AUC': [], 'SVM_MCC': [],\n",
    "            'DT_Top2': [], 'DT_AUC': [], 'DT_MCC': [],\n",
    "            'RF_Top2': [], 'RF_AUC': [], 'RF_MCC': [],\n",
    "        },\n",
    "        '011': {\n",
    "            'LR_Top2': [], 'LR_AUC': [], 'LR_MCC': [],\n",
    "            'NB_Top2': [], 'NB_AUC': [], 'NB_MCC': [],\n",
    "            'SVM_Top2': [], 'SVM_AUC': [], 'SVM_MCC': [],\n",
    "            'DT_Top2': [], 'DT_AUC': [], 'DT_MCC': [],\n",
    "            'RF_Top2': [], 'RF_AUC': [], 'RF_MCC': [],\n",
    "        },\n",
    "        '100': {\n",
    "            'LR_Top2': [], 'LR_AUC': [], 'LR_MCC': [],\n",
    "            'NB_Top2': [], 'NB_AUC': [], 'NB_MCC': [],\n",
    "            'SVM_Top2': [], 'SVM_AUC': [], 'SVM_MCC': [],\n",
    "            'DT_Top2': [], 'DT_AUC': [], 'DT_MCC': [],\n",
    "            'RF_Top2': [], 'RF_AUC': [], 'RF_MCC': [],\n",
    "        },\n",
    "        '101': {\n",
    "            'LR_Top2': [], 'LR_AUC': [], 'LR_MCC': [],\n",
    "            'NB_Top2': [], 'NB_AUC': [], 'NB_MCC': [],\n",
    "            'SVM_Top2': [], 'SVM_AUC': [], 'SVM_MCC': [],\n",
    "            'DT_Top2': [], 'DT_AUC': [], 'DT_MCC': [],\n",
    "            'RF_Top2': [], 'RF_AUC': [], 'RF_MCC': [],\n",
    "        },\n",
    "        '110': {\n",
    "            'LR_Top2': [], 'LR_AUC': [], 'LR_MCC': [],\n",
    "            'NB_Top2': [], 'NB_AUC': [], 'NB_MCC': [],\n",
    "            'SVM_Top2': [], 'SVM_AUC': [], 'SVM_MCC': [],\n",
    "            'DT_Top2': [], 'DT_AUC': [], 'DT_MCC': [],\n",
    "            'RF_Top2': [], 'RF_AUC': [], 'RF_MCC': [],\n",
    "        },\n",
    "        '111': {\n",
    "            'LR_Top2': [], 'LR_AUC': [], 'LR_MCC': [],\n",
    "            'NB_Top2': [], 'NB_AUC': [], 'NB_MCC': [],\n",
    "            'SVM_Top2': [], 'SVM_AUC': [], 'SVM_MCC': [],\n",
    "            'DT_Top2': [], 'DT_AUC': [], 'DT_MCC': [],\n",
    "            'RF_Top2': [], 'RF_AUC': [], 'RF_MCC': [],\n",
    "        },\n",
    "    }\n",
    "    for file_path in file_List:\n",
    "        df = pd.read_csv(file_path)\n",
    "        # print(\"df=\", df)\n",
    "        for index, row in df.iterrows():\n",
    "            binValue = str(\n",
    "                f\"{row['Atom-type']}\" +\n",
    "                f\"{row['Atom-based']}\" +\n",
    "                f\"{row['Topol-based']}\"\n",
    "            )\n",
    "            if row['Performa nce metrics'] == 'Top2':\n",
    "                newDict[binValue]['LR_Top2'].append(df['LR'][index])\n",
    "                newDict[binValue]['NB_Top2'].append(df['NB'][index])\n",
    "                newDict[binValue]['SVM_Top2'].append(df['SVM'][index])\n",
    "                newDict[binValue]['DT_Top2'].append(df['DT'][index])\n",
    "                newDict[binValue]['RF_Top2'].append(df['RF'][index])\n",
    "    \n",
    "            if row['Performa nce metrics'] == 'AUC':\n",
    "                newDict[binValue]['LR_AUC'].append(df['LR'][index])\n",
    "                newDict[binValue]['NB_AUC'].append(df['NB'][index])\n",
    "                newDict[binValue]['SVM_AUC'].append(df['SVM'][index])\n",
    "                newDict[binValue]['DT_AUC'].append(df['DT'][index])\n",
    "                newDict[binValue]['RF_AUC'].append(df['RF'][index])\n",
    "            if row['Performa nce metrics'] == 'MCC':\n",
    "                newDict[binValue]['LR_MCC'].append(df['LR'][index])\n",
    "                newDict[binValue]['NB_MCC'].append(df['NB'][index])\n",
    "                newDict[binValue]['SVM_MCC'].append(df['SVM'][index])\n",
    "                newDict[binValue]['DT_MCC'].append(df['DT'][index])\n",
    "                newDict[binValue]['RF_MCC'].append(df['RF'][index])\n",
    "    return newDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "202a94f6-117a-42d7-a2e6-9455bdf49b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_data_Dict(file_dir, suffix, save_dir, index):\n",
    "    newDict = get_new_dict(file_dir, suffix)\n",
    "    new_data_dict = pd.DataFrame(\n",
    "    columns=[\n",
    "        'Atom-type', 'Atom-based', 'Topol-based',\n",
    "        'Performa nce metrics',\n",
    "        'LR_mean', 'LR_variance',\n",
    "        'NB_mean', 'NB_variance',\n",
    "        'SVM_mean', 'SVM_variance',\n",
    "        'DT_mean', 'DT_variance',\n",
    "        'RF_mean', 'RF_variance'\n",
    "    ])\n",
    "    Atom_type = []\n",
    "    Atom_based = []\n",
    "    Topol_based = []\n",
    "    Performa_nce_metrics = []\n",
    "    LR_mean = []\n",
    "    LR_variance = []\n",
    "    NB_mean = []\n",
    "    NB_variance = []\n",
    "    SVM_mean = []\n",
    "    SVM_variance = []\n",
    "    DT_mean = []\n",
    "    DT_variance = []\n",
    "    RF_mean = []\n",
    "    RF_variance = []\n",
    "\n",
    "    for i in range(8):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        else:\n",
    "            binNumber = bin(i)[2:].zfill(3)\n",
    "            old_traits_ = list(binNumber)\n",
    "            traits_ = ''.join(old_traits_)\n",
    "            Atom_type.extend([old_traits_[0], old_traits_[0], old_traits_[0]])\n",
    "            Atom_based.extend([old_traits_[1], old_traits_[1], old_traits_[1]])\n",
    "            Topol_based.extend([old_traits_[2], old_traits_[2], old_traits_[2]])\n",
    "            Performa_nce_metrics.append('Top2')\n",
    "            Performa_nce_metrics.append('AUC')\n",
    "            Performa_nce_metrics.append('MCC')\n",
    "            newDict[traits_]['LR_mean'] = [\n",
    "                round(statistics.mean(newDict[traits_]['LR_Top2']), 1),\n",
    "                round(statistics.mean(newDict[traits_]['LR_AUC']), 3),\n",
    "                round(statistics.mean(newDict[traits_]['LR_MCC']), 3),\n",
    "            ]\n",
    "            LR_mean.extend(newDict[traits_]['LR_mean'])\n",
    "            newDict[traits_]['LR_variance'] = [\n",
    "                round(statistics.variance(newDict[traits_]['LR_Top2']), 1),\n",
    "                round(statistics.variance(newDict[traits_]['LR_AUC']), 3),\n",
    "                round(statistics.variance(newDict[traits_]['LR_MCC']), 3),\n",
    "            ]\n",
    "            LR_variance.extend(newDict[traits_]['LR_variance'])\n",
    "            newDict[traits_]['NB_mean'] = [\n",
    "                round(statistics.mean(newDict[traits_]['NB_Top2']), 1),\n",
    "                round(statistics.mean(newDict[traits_]['NB_AUC']), 3),\n",
    "                round(statistics.mean(newDict[traits_]['NB_MCC']), 3),\n",
    "            ]\n",
    "            NB_mean.extend(newDict[traits_]['NB_mean'])\n",
    "            newDict[traits_]['NB_variance'] = [\n",
    "                round(statistics.variance(newDict[traits_]['NB_Top2']), 1),\n",
    "                round(statistics.variance(newDict[traits_]['NB_AUC']), 3),\n",
    "                round(statistics.variance(newDict[traits_]['NB_MCC']), 3),\n",
    "            ]\n",
    "            NB_variance.extend(newDict[traits_]['NB_variance'])\n",
    "            newDict[traits_]['SVM_mean'] = [\n",
    "                round(statistics.mean(newDict[traits_]['SVM_Top2']), 1),\n",
    "                round(statistics.mean(newDict[traits_]['SVM_AUC']), 3),\n",
    "                round(statistics.mean(newDict[traits_]['SVM_MCC']), 3),\n",
    "            ]\n",
    "            SVM_mean.extend(newDict[traits_]['SVM_mean'])\n",
    "    \n",
    "            newDict[traits_]['SVM_variance'] = [\n",
    "                round(statistics.variance(newDict[traits_]['SVM_Top2']), 1),\n",
    "                round(statistics.variance(newDict[traits_]['SVM_AUC']), 3),\n",
    "                round(statistics.variance(newDict[traits_]['SVM_MCC']), 3),\n",
    "            ]\n",
    "            SVM_variance.extend(newDict[traits_]['SVM_variance'])\n",
    "            newDict[traits_]['DT_mean'] = [\n",
    "                round(statistics.mean(newDict[traits_]['DT_Top2']), 1),\n",
    "                round(statistics.mean(newDict[traits_]['DT_AUC']), 3),\n",
    "                round(statistics.mean(newDict[traits_]['DT_MCC']), 3),\n",
    "            ]\n",
    "            DT_mean.extend(newDict[traits_]['DT_mean'])\n",
    "            newDict[traits_]['DT_variance'] = [\n",
    "                round(statistics.variance(newDict[traits_]['DT_Top2']), 1),\n",
    "                round(statistics.variance(newDict[traits_]['DT_AUC']), 3),\n",
    "                round(statistics.variance(newDict[traits_]['DT_MCC']), 3),\n",
    "            ]\n",
    "            DT_variance.extend(newDict[traits_]['DT_variance'])\n",
    "            newDict[traits_]['RF_mean'] = [\n",
    "                round(statistics.mean(newDict[traits_]['RF_Top2']), 1),\n",
    "                round(statistics.mean(newDict[traits_]['RF_AUC']), 3),\n",
    "                round(statistics.mean(newDict[traits_]['RF_MCC']), 3),\n",
    "            ]\n",
    "            RF_mean.extend(newDict[traits_]['RF_mean'])\n",
    "            newDict[traits_]['RF_variance'] = [\n",
    "                round(statistics.variance(newDict[traits_]['RF_Top2']), 1),\n",
    "                round(statistics.variance(newDict[traits_]['RF_AUC']), 3),\n",
    "                round(statistics.variance(newDict[traits_]['RF_MCC']), 3),\n",
    "            ]\n",
    "            RF_variance.extend(newDict[traits_]['RF_variance'])\n",
    "\n",
    "    new_data_dict['Atom-type'] = Atom_type\n",
    "    new_data_dict['Atom-based'] = Atom_based\n",
    "    new_data_dict['Topol-based'] = Topol_based\n",
    "    new_data_dict['Performa nce metrics'] = Performa_nce_metrics\n",
    "    max_len = max(\n",
    "        len(LR_mean), len(LR_variance),\n",
    "        len(NB_mean), len(NB_variance),\n",
    "        len(SVM_mean), len(SVM_variance),\n",
    "        len(DT_mean), len(DT_variance),\n",
    "        len(RF_mean), len(RF_variance))\n",
    "    new_data_dict['LR_mean'] = LR_mean if len(LR_mean) == max_len else [None for i in range(max_len)]\n",
    "    new_data_dict['LR_variance'] = LR_variance if len(LR_variance) == max_len else [None for i in range(max_len)]\n",
    "    new_data_dict['NB_mean'] = NB_mean if len(NB_mean) == max_len else [None for i in range(max_len)]\n",
    "    new_data_dict['NB_variance'] = NB_variance if len(NB_variance) == max_len else [None for i in range(max_len)]\n",
    "    new_data_dict['SVM_mean'] = SVM_mean if len(SVM_mean) == max_len else [None for i in range(max_len)]\n",
    "    new_data_dict['SVM_variance'] = SVM_variance if len(SVM_variance) == max_len else [None for i in range(max_len)]\n",
    "    new_data_dict['DT_mean'] = DT_mean if len(DT_mean) == max_len else [None for i in range(max_len)]\n",
    "    new_data_dict['DT_variance'] = DT_variance if len(DT_variance) == max_len else [None for i in range(max_len)]\n",
    "    new_data_dict['RF_mean'] = RF_mean if len(RF_mean) == max_len else [None for i in range(max_len)]\n",
    "    new_data_dict['RF_variance'] = RF_variance if len(RF_variance) == max_len else [None for i in range(max_len)]\n",
    "    save_path = os.path.join(save_dir, f'mean_vs_variance{index}.csv')\n",
    "    print('save_path = ', save_path)\n",
    "    new_data_dict.to_csv(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69331d2-3fef-4f56-b732-1fb57ec845b6",
   "metadata": {},
   "source": [
    "# 1 Calculate the score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d959e99-0656-4020-a431-8782f08e299e",
   "metadata": {},
   "source": [
    "## 1.1 Calculate the Top2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "634ac4f2-c706-4a2f-b08e-0106f4564717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_topk(a, k, axis=-1, largest=True, sorted_=True):\n",
    "    if axis is None:\n",
    "        axis_size = a.size\n",
    "    else:\n",
    "        axis_size = a.shape[axis]\n",
    "    assert 1 <= k <= axis_size\n",
    "\n",
    "    a = np.asanyarray(a)\n",
    "    if largest:\n",
    "        index_array = np.argpartition(a, axis_size-k, axis=axis)\n",
    "        topk_indices = np.take(index_array, -np.arange(k)-1, axis=axis)\n",
    "    else:\n",
    "        index_array = np.argpartition(a, k-1, axis=axis)\n",
    "        topk_indices = np.take(index_array, np.arange(k), axis=axis)\n",
    "    topk_values = np.take_along_axis(a, topk_indices, axis=axis)\n",
    "    if sorted_:\n",
    "        sorted_indices_in_topk = np.argsort(topk_values, axis=axis)\n",
    "        if largest:\n",
    "            sorted_indices_in_topk = np.flip(sorted_indices_in_topk, axis=axis)\n",
    "        sorted_topk_values = np.take_along_axis(\n",
    "            topk_values, sorted_indices_in_topk, axis=axis)\n",
    "        sorted_topk_indices = np.take_along_axis(\n",
    "            topk_indices, sorted_indices_in_topk, axis=axis)\n",
    "        return sorted_topk_values, sorted_topk_indices\n",
    "    return topk_values, topk_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18fcb2c-0ea2-46dc-9f89-d7e9984e0c27",
   "metadata": {},
   "source": [
    "# 2.1 Set up the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7945822c-4f07-4491-a531-f96b8668409c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_node_features(\n",
    "        mol,\n",
    "        traits=None,\n",
    "):\n",
    "    if traits is None:\n",
    "        traits = [True, True, True]\n",
    "    all_node_feats = []\n",
    "    identity = {\n",
    "        'C': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        'N': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        'O': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "        'F': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "        'P': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "        'S': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "        'Cl': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "        'Br': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "        'I': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "        'other': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "    }\n",
    "    for atom in mol.GetAtoms():\n",
    "        node_feats = []\n",
    "        # atom number\n",
    "        idx = atom.GetIdx()\n",
    "\n",
    "        # Atom-type\n",
    "        if traits[0]:\n",
    "            # atom type one-hot 10\n",
    "            node_feats.extend(identity.get(atom.GetSymbol(), [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]))\n",
    "\n",
    "        # Atom-based\n",
    "        if traits[1]:\n",
    "            # implicit valence\n",
    "            node_feats.append(atom.GetImplicitValence())\n",
    "            # formal charge\n",
    "            node_feats.append(atom.GetFormalCharge())\n",
    "            # radical electrons\n",
    "            node_feats.append(atom.GetNumRadicalElectrons())\n",
    "            # aromatic 0 or 1\n",
    "            if atom.GetIsAromatic():\n",
    "                node_feats.append(1)\n",
    "            else:\n",
    "                node_feats.append(0)\n",
    "\n",
    "            # chirality\n",
    "            chirality = atom.GetChiralTag()\n",
    "            temp = None\n",
    "            if chirality == ChiralType.CHI_TETRAHEDRAL_CCW: temp = [1, 0, 0, 0]\n",
    "            if chirality == ChiralType.CHI_TETRAHEDRAL_CW: temp = [0, 1, 0, 0]\n",
    "            if chirality == ChiralType.CHI_OTHER: temp = [0, 0, 1, 0]\n",
    "            if chirality == ChiralType.CHI_UNSPECIFIED: temp = [0, 0, 0, 1]\n",
    "            node_feats.extend(temp)\n",
    "            # hybridization\n",
    "            hybridization = atom.GetHybridization()\n",
    "            tmp = None\n",
    "            if hybridization == HybridizationType.S: tmp = [1, 0, 0, 0, 0, 0, 0, 0]\n",
    "            if hybridization == HybridizationType.SP: tmp = [0, 1, 0, 0, 0, 0, 0, 0]\n",
    "            if hybridization == HybridizationType.SP2: tmp = [0, 0, 1, 0, 0, 0, 0, 0]\n",
    "            if hybridization == HybridizationType.SP3: tmp = [0, 0, 0, 1, 0, 0, 0, 0]\n",
    "            if hybridization == HybridizationType.SP3D: tmp = [0, 0, 0, 0, 1, 0, 0, 0]\n",
    "            if hybridization == HybridizationType.SP3D2: tmp = [0, 0, 0, 0, 0, 1, 0, 0]\n",
    "            if hybridization == HybridizationType.OTHER: tmp = [0, 0, 0, 0, 0, 0, 1, 0]\n",
    "            if hybridization == HybridizationType.UNSPECIFIED: tmp = [0, 0, 0, 0, 0, 0, 0, 1]\n",
    "            node_feats.extend(tmp)\n",
    "\n",
    "        # Topol-based\n",
    "        if traits[2]:\n",
    "            # degree\n",
    "            node_feats.append(atom.GetDegree())\n",
    "            # hydrogen\n",
    "            node_feats.append(atom.GetTotalNumHs())\n",
    "            # ring status 0 or 1\n",
    "            if atom.IsInRing():\n",
    "                node_feats.append(1)\n",
    "            else:\n",
    "                node_feats.append(0)\n",
    "        # Append node features to matrix\n",
    "        all_node_feats.append(node_feats)\n",
    "\n",
    "    all_node_feats = np.asarray(all_node_feats, dtype=np.float64)\n",
    "    return all_node_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab67176c-b309-4717-b491-bc5f87a0df36",
   "metadata": {},
   "source": [
    "## 2.2 Get feature labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75435636-bd13-45b3-946a-937eecbe0270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_labels(mol):\n",
    "    _y = []\n",
    "    som = ['PRIMARY_SOM_1A2', 'PRIMARY_SOM_2A6', 'PRIMARY_SOM_2B6', 'PRIMARY_SOM_2C8', 'PRIMARY_SOM_2C9',\n",
    "           'PRIMARY_SOM_2C19', 'PRIMARY_SOM_2D6', 'PRIMARY_SOM_2E1', 'PRIMARY_SOM_3A4',\n",
    "           'SECONDARY_SOM_1A2', 'SECONDARY_SOM_2A6', 'SECONDARY_SOM_2B6', 'SECONDARY_SOM_2C8', 'SECONDARY_SOM_2C9',\n",
    "           'SECONDARY_SOM_2C19', 'SECONDARY_SOM_2D6', 'SECONDARY_SOM_2E1', 'SECONDARY_SOM_3A4',\n",
    "           'TERTIARY_SOM_1A2', 'TERTIARY_SOM_2A6', 'TERTIARY_SOM_2B6', 'TERTIARY_SOM_2C8', 'TERTIARY_SOM_2C9',\n",
    "           'TERTIARY_SOM_2C19', 'TERTIARY_SOM_2D6', 'TERTIARY_SOM_2E1', 'TERTIARY_SOM_3A4'\n",
    "           ]\n",
    "    result = []\n",
    "    for k in som:\n",
    "        try:\n",
    "            _res = mol.GetProp(k)\n",
    "            if ' ' in _res:\n",
    "                res = _res.split(' ')\n",
    "                for s in res:\n",
    "                    result.append(int(s))\n",
    "            else:\n",
    "                result.append(int(_res))\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    for data in result:\n",
    "        _y.append(data)\n",
    "    _y = list(set(_y))\n",
    "\n",
    "    y = np.zeros(len(mol.GetAtoms()))\n",
    "    for i in _y:\n",
    "        y[i - 1] = 1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456dadab-ef60-47ef-98b2-5a35f72fbc4a",
   "metadata": {},
   "source": [
    "## 2.3 Obtain molecular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe19953e-9ba0-4e87-81ad-d3eab266d96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mol_data(\n",
    "        file_path: str = None,\n",
    "        train_number: int = 544,\n",
    "        index: int = 0\n",
    "):\n",
    "    raws = Chem.SDMolSupplier(file_path)\n",
    "    mols = [mol for mol in raws]\n",
    "    # Set up a random seed to ensure the results are reproducible.\n",
    "    random.seed(randomNumber)\n",
    "    # Shuffle the order.\n",
    "    random.shuffle(mols)\n",
    "    mols_train = mols[:train_number]\n",
    "    mols_test = mols[train_number:]\n",
    "    return mols_train, mols_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bed058b-9007-4c92-b05f-df7c13ae7b8c",
   "metadata": {},
   "source": [
    "## 2.4 Set up collection data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3932c575-ae8a-478a-b142-1c652b587858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_set_data(mols_train, mols_test, traits=None):\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "    te_indices = []\n",
    "    for mol in mols_train:\n",
    "        mol_feature = _get_node_features(mol=mol, traits=traits)\n",
    "        label = _get_labels(mol)\n",
    "        train_set.append((mol_feature, label))\n",
    "    for mol in mols_test:\n",
    "        mol_feature = _get_node_features(mol=mol, traits=traits)\n",
    "        label = _get_labels(mol)\n",
    "        test_set.append((mol_feature, label))\n",
    "        te_indices.append(len(label))\n",
    "    return train_set, test_set, te_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9e6be0-c7f7-4eec-b066-578e79e3e017",
   "metadata": {},
   "source": [
    "## 2.5 Set up training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a99543c2-6c2e-4482-9124-73ab76146218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_and_test(train_set, test_set, te_indices):\n",
    "    tr_all = 0  # all training atoms\n",
    "    tr_indices = []  # molecule nums\n",
    "    y_train = []  # label\n",
    "    for feature, label in train_set:\n",
    "        tr_all += feature.shape[0]\n",
    "        tr_indices.append(len(label))\n",
    "        y_train.extend(label)\n",
    "\n",
    "    x_train = np.zeros((tr_all, train_set[0][0].shape[1]))\n",
    "    pre = 0\n",
    "    for i in range(len(tr_indices)):\n",
    "        if i == 0:\n",
    "            x_train[:tr_indices[i], :] = train_set[i][0]\n",
    "        else:\n",
    "            j = i - 1\n",
    "            pre += tr_indices[j]\n",
    "            x_train[pre:pre + tr_indices[i], :] = train_set[i][0]\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    # Stitching matrix\n",
    "    te_all = 0\n",
    "    y_test = []\n",
    "    for feature, label in test_set:\n",
    "        te_all += feature.shape[0]\n",
    "        y_test.extend(label)\n",
    "    x_test = np.zeros((te_all, train_set[0][0].shape[1]))\n",
    "    pre = 0\n",
    "    for i in range(len(te_indices)):\n",
    "        if i == 0:\n",
    "            x_test[:te_indices[i], :] = test_set[i][0]\n",
    "        else:\n",
    "            j = i - 1\n",
    "            pre += te_indices[j]\n",
    "            x_test[pre:pre + te_indices[i], :] = test_set[i][0]\n",
    "    y_test = np.array(y_test)\n",
    "    return x_train, y_train, x_test, y_test,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9f5adc-b5af-4f87-b1b4-6b87b3831332",
   "metadata": {},
   "source": [
    "# 3 Machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218f8e91-d52b-44b8-9cc8-238cdd98915f",
   "metadata": {},
   "source": [
    "## 3.1 Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3a8da87-f74d-4c08-9fbf-9ee960319cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_lr(x_train, y_train, x_test, y_test, test_set, te_indices, index: int, save_model_path: str):\n",
    "    name = os.path.basename(save_model_path).split('.')[0]\n",
    "    \n",
    "    if os.path.exists(save_model_path):\n",
    "        clf = joblib.load(save_model_path)\n",
    "    else:\n",
    "        max_iter = 20 + 5 * index\n",
    "        # C = 6 + index\n",
    "        clf = LogisticRegression(\n",
    "            C=10,\n",
    "            solver='sag',\n",
    "            random_state=randomNumber,\n",
    "            class_weight='balanced',\n",
    "            max_iter=max_iter,\n",
    "            n_jobs=-1\n",
    "        ).fit(x_train, y_train)\n",
    "        joblib.dump(clf, save_model_path)\n",
    "    preds = clf.predict(x_test)\n",
    "    logits = clf.predict_proba(x_test)\n",
    "    top2 = 0\n",
    "    pre = 0\n",
    "    for i in range(len(te_indices)):\n",
    "        if i == 0:\n",
    "            y_preds = logits[:te_indices[i], :][:, 1]\n",
    "            topk_values, topk_indices = find_topk(y_preds, 2)\n",
    "            for a in range(len(test_set[i][1])):\n",
    "                if test_set[i][1][a] == 1 and a in topk_indices:\n",
    "                    top2 += 1\n",
    "                    break\n",
    "        else:\n",
    "            j = i - 1\n",
    "            pre += te_indices[j]\n",
    "            y_preds = logits[pre:pre + te_indices[i], :][:, 1]\n",
    "            topk_values, topk_indices = find_topk(y_preds, 2)\n",
    "            for a in range(len(test_set[i][1])):\n",
    "                if test_set[i][1][a] == 1 and a in topk_indices:\n",
    "                    top2 += 1\n",
    "                    break\n",
    "    return {\n",
    "        'Top2': round(top2 *100 / len(test_set), 3),\n",
    "        'AUC': round(roc_auc_score(y_test, preds), 3),\n",
    "        'MCC': round(matthews_corrcoef(y_test, preds), 3),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce74bd40-000b-40f1-a5d1-39485720bf88",
   "metadata": {},
   "source": [
    "## 3.2 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6adbd14b-684c-462a-9457-d243f8afc3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_nb(x_train, y_train, x_test, y_test, test_set, te_indices, index: int, save_model_path: str):\n",
    "    if os.path.exists(save_model_path):\n",
    "        clf = joblib.load(save_model_path)\n",
    "    else:\n",
    "        var_smoothing = 0.0000000001 * math.pow(10, index+1)\n",
    "        clf = GaussianNB(var_smoothing=var_smoothing)\n",
    "        clf.fit(x_train, y_train)\n",
    "        joblib.dump(clf, save_model_path)\n",
    "    preds = clf.predict(x_test)\n",
    "    logits = clf.predict_proba(x_test)\n",
    "    top2 = 0\n",
    "    pre = 0\n",
    "    for i in range(len(te_indices)):\n",
    "        if i == 0:\n",
    "            y_preds = logits[:te_indices[i], :][:, 1]\n",
    "            topk_values, topk_indices = find_topk(y_preds, 2)\n",
    "            for a in range(len(test_set[i][1])):\n",
    "                if test_set[i][1][a] == 1 and a in topk_indices:\n",
    "                    top2 += 1\n",
    "                    break\n",
    "        else:\n",
    "            j = i - 1\n",
    "            pre += te_indices[j]\n",
    "            y_preds = logits[pre:pre + te_indices[i], :][:, 1]\n",
    "            topk_values, topk_indices = find_topk(y_preds, 2)\n",
    "            for a in range(len(test_set[i][1])):\n",
    "                if test_set[i][1][a] == 1 and a in topk_indices:\n",
    "                    top2 += 1\n",
    "                    break\n",
    "    return {\n",
    "        'Top2': round(top2 *100 / len(test_set), 3),\n",
    "        'AUC': round(roc_auc_score(y_test, preds), 3),\n",
    "        'MCC': round(matthews_corrcoef(y_test, preds), 3),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fade4751-c02c-49af-bd93-15b0b27122ff",
   "metadata": {},
   "source": [
    "## 3.3 Support vector machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87065dc9-dfd5-4921-9259-500eb47d1a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_svm(x_train, y_train, x_test, y_test, test_set, te_indices, index: int, save_model_path: str):\n",
    "    if os.path.exists(save_model_path):\n",
    "        clf = joblib.load(save_model_path)\n",
    "    else:\n",
    "        C = 0.06 + 0.01 * index\n",
    "        clf = SVC(\n",
    "            C=C,\n",
    "            degree=2,\n",
    "            gamma='scale',\n",
    "            kernel='linear',\n",
    "            random_state=randomNumber,\n",
    "            class_weight='balanced',\n",
    "            probability=True).fit(x_train, y_train)\n",
    "    joblib.dump(clf, save_model_path)\n",
    "    preds = clf.predict(x_test)\n",
    "    logits = clf.predict_proba(x_test)\n",
    "    top2 = 0\n",
    "    pre = 0\n",
    "    for i in range(len(te_indices)):\n",
    "        if i == 0:\n",
    "            y_preds = logits[:te_indices[i], :][:, 1]\n",
    "            topk_values, topk_indices = find_topk(y_preds, 2)\n",
    "            for a in range(len(test_set[i][1])):\n",
    "                if test_set[i][1][a] == 1 and a in topk_indices:\n",
    "                    top2 += 1\n",
    "                    break\n",
    "        else:\n",
    "            j = i - 1\n",
    "            pre += te_indices[j]\n",
    "            y_preds = logits[pre:pre + te_indices[i], :][:, 1]\n",
    "            topk_values, topk_indices = find_topk(y_preds, 2)\n",
    "            for a in range(len(test_set[i][1])):\n",
    "                if test_set[i][1][a] == 1 and a in topk_indices:\n",
    "                    top2 += 1\n",
    "                    break\n",
    "    return {\n",
    "        'Top2': round(top2 *100 / len(test_set), 3),\n",
    "        'AUC': round(roc_auc_score(y_test, preds), 3),\n",
    "        'MCC': round(matthews_corrcoef(y_test, preds), 3),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e8ad8b-aaff-44b7-a35d-7cc0bd574ea5",
   "metadata": {},
   "source": [
    "## 3.4 Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ee01ad4-c19d-42cb-8abf-8e98303abdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_dt(x_train, y_train, x_test, y_test, test_set, te_indices, index: int, save_model_path: str):\n",
    "    if os.path.exists(save_model_path):\n",
    "        clf = joblib.load(save_model_path)\n",
    "    else:\n",
    "        max_depths = 1 + index\n",
    "        clf = DecisionTreeClassifier(\n",
    "            random_state=randomNumber,\n",
    "            class_weight='balanced',\n",
    "            criterion='gini',\n",
    "            max_depth=max_depths,\n",
    "            splitter='best'\n",
    "        ).fit(x_train, y_train)\n",
    "        joblib.dump(clf, save_model_path)\n",
    "    preds = clf.predict(x_test)\n",
    "    logits = clf.predict_proba(x_test)\n",
    "    top2 = 0\n",
    "    pre = 0\n",
    "    for i in range(len(te_indices)):\n",
    "        if i == 0:\n",
    "            y_preds = logits[:te_indices[i], :][:, 1]\n",
    "            topk_values, topk_indices = find_topk(y_preds, 2)\n",
    "            for a in range(len(test_set[i][1])):\n",
    "                if test_set[i][1][a] == 1 and a in topk_indices:\n",
    "                    top2 += 1\n",
    "                    break\n",
    "        else:\n",
    "            j = i - 1\n",
    "            pre += te_indices[j]\n",
    "            y_preds = logits[pre:pre + te_indices[i], :][:, 1]\n",
    "            topk_values, topk_indices = find_topk(y_preds, 2)\n",
    "            for a in range(len(test_set[i][1])):\n",
    "                if test_set[i][1][a] == 1 and a in topk_indices:\n",
    "                    top2 += 1\n",
    "                    break\n",
    "    return {\n",
    "        'Top2': round(top2 *100 / len(test_set), 3),\n",
    "        'AUC': round(roc_auc_score(y_test, preds), 3),\n",
    "        'MCC': round(matthews_corrcoef(y_test, preds), 3),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8840abdc-344f-4e1c-9220-82d3e97332a4",
   "metadata": {},
   "source": [
    "## 3.5 Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c28a809-b260-44df-a394-dd68f5899b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_rf(x_train, y_train, x_test, y_test, test_set, te_indices, index: int, save_model_path: str):\n",
    "    if os.path.exists(save_model_path):\n",
    "        clf = joblib.load(save_model_path)\n",
    "    else:\n",
    "        n_estimators = 50 + 15 * index\n",
    "        clf = RandomForestClassifier(\n",
    "            random_state=randomNumber,\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=20,\n",
    "            criterion='entropy',\n",
    "            class_weight='balanced'\n",
    "        ).fit(x_train, y_train)\n",
    "        joblib.dump(clf, save_model_path)\n",
    "    preds = clf.predict(x_test)\n",
    "    logits = clf.predict_proba(x_test)\n",
    "    top2 = 0\n",
    "    pre = 0\n",
    "    for i in range(len(te_indices)):\n",
    "        if i == 0:\n",
    "            # 取出第一列，\n",
    "            y_preds = logits[:te_indices[i], :][:, 1]\n",
    "            topk_values, topk_indices = find_topk(y_preds, 2)\n",
    "            for a in range(len(test_set[i][1])):\n",
    "                if test_set[i][1][a] == 1 and a in topk_indices:\n",
    "                    top2 += 1\n",
    "                    break\n",
    "        else:\n",
    "            j = i - 1\n",
    "            pre += te_indices[j]\n",
    "            y_preds = logits[pre:pre + te_indices[i], :][:, 1]\n",
    "            topk_values, topk_indices = find_topk(y_preds, 2)\n",
    "            for a in range(len(test_set[i][1])):\n",
    "                if test_set[i][1][a] == 1 and a in topk_indices:\n",
    "                    top2 += 1\n",
    "                    break\n",
    "    return {\n",
    "        'Top2': round(top2 *100 / len(test_set), 3),\n",
    "        'AUC': round(roc_auc_score(y_test, preds), 3),\n",
    "        'MCC': round(matthews_corrcoef(y_test, preds), 3),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5601f372-1b2b-4e07-a016-a8101efd7ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(file_path, modelsDir, resultDir, newResultsDir, number: int = 1):\n",
    "    if not os.path.exists(modelDir): os.mkdir(modelDir)\n",
    "    if not os.path.exists(resultsDir): os.mkdir(resultsDir)\n",
    "    if not os.path.exists(newResultsDir): os.mkdir(newResultsDir)\n",
    "    for index_ in range(number):\n",
    "        molsTrain, molsTest = get_mol_data(filepath, train_number=544)\n",
    "        newModelDir = os.path.join(modelDir, os.path.basename(modelDir) + str(index_))\n",
    "        if not os.path.exists(newModelDir):\n",
    "            os.mkdir(newModelDir)\n",
    "        DataFrameSet = pd.DataFrame(\n",
    "            columns=[\n",
    "                'Atom-type', 'Atom-based', 'Topol-based',\n",
    "                'Performa nce metrics',\n",
    "                'LR', 'NB', 'SVM', 'DT', 'RF'])\n",
    "        Atom_type = []\n",
    "        Atom_based = []\n",
    "        Topol_based = []\n",
    "        Performa_nce_metrics = []\n",
    "        LR = []\n",
    "        NB = []\n",
    "        SVM = []\n",
    "        DT = []\n",
    "        RF = []\n",
    "        mix = 8\n",
    "        if os.path.exists(os.path.join(resultsDir, f'result_{index_}.csv')):\n",
    "            continue\n",
    "        for i in tqdm(range(mix), total=mix, desc=f'Number of trainings[{number}/{index_}]'):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            # elif i == 4:\n",
    "            #     continue\n",
    "            else:\n",
    "                binNumber = bin(i)[2:].zfill(3)\n",
    "                traits_ = list(binNumber)\n",
    "                traits_ = [int(j) for j in traits_]\n",
    "                Atom_type.extend([traits_[0], traits_[0], traits_[0]])\n",
    "                Atom_based.extend([traits_[1], traits_[1], traits_[1]])\n",
    "                Topol_based.extend([traits_[2], traits_[2], traits_[2]])\n",
    "                trainSet, testSet, teIndices = get_set_data(molsTrain, molsTest, traits=traits_)\n",
    "                xTrain, yTrain, xTest, yTest = get_train_and_test(trainSet, testSet, teIndices)\n",
    "                Performa_nce_metrics.append('Top2')\n",
    "                Performa_nce_metrics.append('AUC')\n",
    "                Performa_nce_metrics.append('MCC')\n",
    "                # print('Logistic regression prediction...')\n",
    "                newSaveDir = os.path.join(newModelDir, 'LR')\n",
    "                if not os.path.exists(newSaveDir): os.mkdir(newSaveDir)\n",
    "                newSavePath = os.path.join(newSaveDir, f'LR_{str(binNumber)}.joblib')\n",
    "                lrScores = ml_lr(xTrain, yTrain, xTest, yTest, testSet, teIndices, index_, newSavePath)\n",
    "                for key, item in lrScores.items():\n",
    "                    LR.append(item)\n",
    "                # print('Naive Bayes predicts...')\n",
    "                newSaveDir = os.path.join(newModelDir, 'NB')\n",
    "                if not os.path.exists(newSaveDir): os.mkdir(newSaveDir)\n",
    "                newSavePath = os.path.join(newSaveDir, f'NB_{str(binNumber)}.joblib')\n",
    "                nbScores = ml_nb(xTrain, yTrain, xTest, yTest, testSet, teIndices, index_, newSavePath)\n",
    "                for key, item in nbScores.items():\n",
    "                    NB.append(item)\n",
    "                # print('Decision tree prediction...')\n",
    "                newSaveDir = os.path.join(newModelDir, 'DT')\n",
    "                if not os.path.exists(newSaveDir): os.mkdir(newSaveDir)\n",
    "                newSavePath = os.path.join(newSaveDir, f'DT_{str(binNumber)}.joblib')\n",
    "                dtScores = ml_dt(xTrain, yTrain, xTest, yTest, testSet, teIndices, index_, newSavePath)\n",
    "                for key, item in dtScores.items():\n",
    "                    DT.append(item)\n",
    "                # print('Random forest predictions...')\n",
    "                newSaveDir = os.path.join(newModelDir, 'RF')\n",
    "                if not os.path.exists(newSaveDir): os.mkdir(newSaveDir)\n",
    "                newSavePath = os.path.join(newSaveDir, f'RF_{str(binNumber)}.joblib')\n",
    "                rfScores = ml_rf(xTrain, yTrain, xTest, yTest, testSet, teIndices, index_, newSavePath)\n",
    "                for key, item in rfScores.items():\n",
    "                    RF.append(item)\n",
    "                # print('Support vector machine prediction...')\n",
    "                newSaveDir = os.path.join(newModelDir, 'SVM')\n",
    "                if not os.path.exists(newSaveDir): os.mkdir(newSaveDir)\n",
    "                newSavePath = os.path.join(newSaveDir, f'SVM_{str(binNumber)}.joblib')\n",
    "                svmScores = ml_svm(xTrain, yTrain, xTest, yTest, testSet, teIndices, index_, newSavePath)\n",
    "                for key, item in svmScores.items():\n",
    "                    SVM.append(item)\n",
    "        DataFrameSet['Atom-type'] = Atom_type\n",
    "        DataFrameSet['Atom-based'] = Atom_based\n",
    "        DataFrameSet['Topol-based'] = Topol_based\n",
    "        DataFrameSet['Performa nce metrics'] = Performa_nce_metrics\n",
    "        max_len = max(len(LR), len(NB), len(SVM), len(DT), len(RF))\n",
    "        DataFrameSet['LR'] = LR if len(LR) == max_len else [None for i in range(max_len)]\n",
    "        DataFrameSet['NB'] = NB if len(NB) == max_len else [None for i in range(max_len)]\n",
    "        DataFrameSet['SVM'] = SVM if len(SVM) == max_len else [None for i in range(max_len)]\n",
    "        DataFrameSet['DT'] = DT if len(DT) == max_len else [None for i in range(max_len)]\n",
    "        DataFrameSet['RF'] = RF if len(RF) == max_len else [None for i in range(max_len)]\n",
    "        DataFrameSet.to_csv(os.path.join(resultsDir, f'result_{index_}.csv'))\n",
    "    # for index_ in range(number):\n",
    "    get_new_data_Dict(resultsDir, 'csv', newResultsDir, 3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9c54f8e-e9ac-44f7-8759-6bb6118666d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/home/dldx/DATA/JXDATA/GitHubProjects/GraphCySoM/datasets/merged.sdf'\n",
    "modelDir = '/home/dldx/DATA/JXDATA/GitHubProjects/GraphCySoM/datasets/models'\n",
    "resultsDir = '/home/dldx/DATA/JXDATA/GitHubProjects/GraphCySoM/datasets/results'\n",
    "newResultsDir = '/home/dldx/DATA/JXDATA/GitHubProjects/GraphCySoM/datasets/mean_vs_variance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b9b2937-e350-4b6f-a4dc-8e47efea3211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_path =  /home/dldx/DATA/JXDATA/GitHubProjects/GraphCySoM/datasets/mean_vs_variance/mean_vs_variance3.csv\n"
     ]
    }
   ],
   "source": [
    "main(filepath, modelDir, resultsDir, newResultsDir, number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cb7c27-de3c-45bb-8bc1-01cea2ee814b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
